{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (18,8)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.core.arrayprint._line_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891221 entries, 0 to 891220\n",
      "Columns: 366 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(93), object(6)\n",
      "memory usage: 2.4+ GB\n",
      "None\n",
      "                LNR       AGER_TYP     AKT_DAT_KL       ALTER_HH  \\\n",
      "count  8.912210e+05  891221.000000  817722.000000  817722.000000   \n",
      "mean   6.372630e+05      -0.358435       4.421928      10.864126   \n",
      "std    2.572735e+05       1.198724       3.638805       7.639683   \n",
      "min    1.916530e+05      -1.000000       1.000000       0.000000   \n",
      "25%    4.144580e+05      -1.000000       1.000000       0.000000   \n",
      "50%    6.372630e+05      -1.000000       3.000000      13.000000   \n",
      "75%    8.600680e+05      -1.000000       9.000000      17.000000   \n",
      "max    1.082873e+06       3.000000       9.000000      21.000000   \n",
      "\n",
      "        ALTER_KIND1   ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
      "count  81058.000000  29499.000000  6170.000000  1205.000000   \n",
      "mean      11.745392     13.402658    14.476013    15.089627   \n",
      "std        4.097660      3.243300     2.712427     2.452932   \n",
      "min        2.000000      2.000000     4.000000     7.000000   \n",
      "25%        8.000000     11.000000    13.000000    14.000000   \n",
      "50%       12.000000     14.000000    15.000000    15.000000   \n",
      "75%       15.000000     16.000000    17.000000    17.000000   \n",
      "max       18.000000     18.000000    18.000000    18.000000   \n",
      "\n",
      "       ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...            VHN  \\\n",
      "count         628274.000000        798073.000000  ...  770025.000000   \n",
      "mean              13.700717             8.287263  ...       2.417322   \n",
      "std                5.079849            15.628087  ...       1.166572   \n",
      "min                0.000000             0.000000  ...       0.000000   \n",
      "25%               11.000000             1.000000  ...       2.000000   \n",
      "50%               14.000000             4.000000  ...       2.000000   \n",
      "75%               17.000000             9.000000  ...       3.000000   \n",
      "max               25.000000           595.000000  ...       4.000000   \n",
      "\n",
      "            VK_DHT4A     VK_DISTANZ        VK_ZG11  W_KEIT_KIND_HH  \\\n",
      "count  815304.000000  815304.000000  815304.000000   783619.000000   \n",
      "mean        6.001214       7.532130       5.945972        3.933406   \n",
      "std         2.856091       3.247789       2.771464        1.964701   \n",
      "min         1.000000       1.000000       1.000000        0.000000   \n",
      "25%         3.000000       5.000000       4.000000        2.000000   \n",
      "50%         6.000000       8.000000       6.000000        4.000000   \n",
      "75%         9.000000      10.000000       8.000000        6.000000   \n",
      "max        11.000000      13.000000      11.000000        6.000000   \n",
      "\n",
      "       WOHNDAUER_2008       WOHNLAGE       ZABEOTYP      ANREDE_KZ  \\\n",
      "count   817722.000000  798073.000000  891221.000000  891221.000000   \n",
      "mean         7.908791       4.052836       3.362438       1.522098   \n",
      "std          1.923137       1.949539       1.352704       0.499512   \n",
      "min          1.000000       0.000000       1.000000       1.000000   \n",
      "25%          8.000000       3.000000       3.000000       1.000000   \n",
      "50%          9.000000       3.000000       3.000000       2.000000   \n",
      "75%          9.000000       5.000000       4.000000       2.000000   \n",
      "max          9.000000       8.000000       6.000000       2.000000   \n",
      "\n",
      "       ALTERSKATEGORIE_GROB  \n",
      "count         891221.000000  \n",
      "mean               2.777398  \n",
      "std                1.068775  \n",
      "min                1.000000  \n",
      "25%                2.000000  \n",
      "50%                3.000000  \n",
      "75%                4.000000  \n",
      "max                9.000000  \n",
      "\n",
      "[8 rows x 360 columns]\n",
      "Wall time: 7min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Load AZDIAS and get summary stats\n",
    "\n",
    "azdias = pd.read_csv('arvato_data/Udacity_AZDIAS_052018.csv',  dtype={18:'str',19:'str'}, sep=';')\n",
    "print(azdias.info())\n",
    "print(azdias.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KK_KUNDENTYP    65.60\n",
      "EXTSEL992       73.40\n",
      "ALTER_KIND1     90.90\n",
      "ALTER_KIND2     96.69\n",
      "ALTER_KIND3     99.31\n",
      "ALTER_KIND4     99.86\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Get list of columns with mostly missing values\n",
    "percent_missing = azdias.isna().mean().round(4) * 100\n",
    "percent_missing.sort_values(inplace=True)\n",
    "drop_list = percent_missing[percent_missing > 30.0 ]\n",
    "print(drop_list)\n",
    "#percent_missing.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99231"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing_rows = azdias.isna().mean(axis=1).round(4) * 100\n",
    "percent_missing_rows.sort_values(inplace=True)\n",
    "percent_missing_rows[percent_missing_rows > 50.0 ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LP_LEBENSPHASE_GROB</th>\n",
       "      <th>LP_FAMILIE_GROB</th>\n",
       "      <th>LP_STATUS_FEIN</th>\n",
       "      <th>LP_STATUS_GROB</th>\n",
       "      <th>KBA13_GBZ</th>\n",
       "      <th>LP_LEBENSPHASE_FEIN</th>\n",
       "      <th>KBA13_FAB_SONSTIGE</th>\n",
       "      <th>KBA13_HHZ</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>PLZ8_GBZ</th>\n",
       "      <th>PLZ8_HHZ</th>\n",
       "      <th>KBA13_KMH_250</th>\n",
       "      <th>KBA13_KMH_211</th>\n",
       "      <th>KBA13_HERST_SONST</th>\n",
       "      <th>LP_FAMILIE_FEIN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LP_LEBENSPHASE_GROB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957661</td>\n",
       "      <td>0.390511</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.989961</td>\n",
       "      <td>-0.069172</td>\n",
       "      <td>-0.069047</td>\n",
       "      <td>-0.177847</td>\n",
       "      <td>0.152153</td>\n",
       "      <td>-0.064933</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.069172</td>\n",
       "      <td>0.942819</td>\n",
       "      <td>-0.177903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP_FAMILIE_GROB</th>\n",
       "      <td>0.957661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234589</td>\n",
       "      <td>0.245960</td>\n",
       "      <td>0.109975</td>\n",
       "      <td>0.941647</td>\n",
       "      <td>-0.058545</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>-0.129295</td>\n",
       "      <td>0.108347</td>\n",
       "      <td>-0.046411</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>-0.004727</td>\n",
       "      <td>-0.058545</td>\n",
       "      <td>0.984100</td>\n",
       "      <td>-0.131622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP_STATUS_FEIN</th>\n",
       "      <td>0.390511</td>\n",
       "      <td>0.234589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982411</td>\n",
       "      <td>0.358554</td>\n",
       "      <td>0.443415</td>\n",
       "      <td>-0.106164</td>\n",
       "      <td>-0.122229</td>\n",
       "      <td>-0.372640</td>\n",
       "      <td>0.356850</td>\n",
       "      <td>-0.109888</td>\n",
       "      <td>0.038974</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>-0.106164</td>\n",
       "      <td>0.236180</td>\n",
       "      <td>-0.367039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP_STATUS_GROB</th>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.245960</td>\n",
       "      <td>0.982411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346147</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>-0.104668</td>\n",
       "      <td>-0.107028</td>\n",
       "      <td>-0.357599</td>\n",
       "      <td>0.344592</td>\n",
       "      <td>-0.095378</td>\n",
       "      <td>0.051409</td>\n",
       "      <td>0.050484</td>\n",
       "      <td>-0.104668</td>\n",
       "      <td>0.241076</td>\n",
       "      <td>-0.351731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBA13_GBZ</th>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.109975</td>\n",
       "      <td>0.358554</td>\n",
       "      <td>0.346147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178266</td>\n",
       "      <td>-0.169633</td>\n",
       "      <td>0.475506</td>\n",
       "      <td>-0.292483</td>\n",
       "      <td>0.979854</td>\n",
       "      <td>0.489083</td>\n",
       "      <td>0.127471</td>\n",
       "      <td>0.127423</td>\n",
       "      <td>-0.169633</td>\n",
       "      <td>0.107839</td>\n",
       "      <td>-0.286385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP_LEBENSPHASE_FEIN</th>\n",
       "      <td>0.989961</td>\n",
       "      <td>0.941647</td>\n",
       "      <td>0.443415</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.178266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>-0.074577</td>\n",
       "      <td>-0.201056</td>\n",
       "      <td>0.176442</td>\n",
       "      <td>-0.069709</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>0.917662</td>\n",
       "      <td>-0.200118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBA13_FAB_SONSTIGE</th>\n",
       "      <td>-0.069172</td>\n",
       "      <td>-0.058545</td>\n",
       "      <td>-0.106164</td>\n",
       "      <td>-0.104668</td>\n",
       "      <td>-0.169633</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>-0.167843</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>-0.014234</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059229</td>\n",
       "      <td>0.063293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBA13_HHZ</th>\n",
       "      <td>-0.069047</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>-0.122229</td>\n",
       "      <td>-0.107028</td>\n",
       "      <td>0.475506</td>\n",
       "      <td>-0.074577</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094123</td>\n",
       "      <td>0.475023</td>\n",
       "      <td>0.968725</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>0.109367</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>-0.047557</td>\n",
       "      <td>0.092390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <td>-0.177847</td>\n",
       "      <td>-0.129295</td>\n",
       "      <td>-0.372640</td>\n",
       "      <td>-0.357599</td>\n",
       "      <td>-0.292483</td>\n",
       "      <td>-0.201056</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>0.094123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.291662</td>\n",
       "      <td>0.086214</td>\n",
       "      <td>-0.024765</td>\n",
       "      <td>-0.023419</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>-0.125571</td>\n",
       "      <td>0.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLZ8_GBZ</th>\n",
       "      <td>0.152153</td>\n",
       "      <td>0.108347</td>\n",
       "      <td>0.356850</td>\n",
       "      <td>0.344592</td>\n",
       "      <td>0.979854</td>\n",
       "      <td>0.176442</td>\n",
       "      <td>-0.167843</td>\n",
       "      <td>0.475023</td>\n",
       "      <td>-0.291662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497958</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>0.126570</td>\n",
       "      <td>-0.167843</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>-0.285719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLZ8_HHZ</th>\n",
       "      <td>-0.064933</td>\n",
       "      <td>-0.046411</td>\n",
       "      <td>-0.109888</td>\n",
       "      <td>-0.095378</td>\n",
       "      <td>0.489083</td>\n",
       "      <td>-0.069709</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.968725</td>\n",
       "      <td>0.086214</td>\n",
       "      <td>0.497958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106652</td>\n",
       "      <td>0.109568</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>-0.045396</td>\n",
       "      <td>0.084674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBA13_KMH_250</th>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0.038974</td>\n",
       "      <td>0.051409</td>\n",
       "      <td>0.127471</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>-0.014234</td>\n",
       "      <td>0.106656</td>\n",
       "      <td>-0.024765</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>0.106652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960155</td>\n",
       "      <td>-0.014234</td>\n",
       "      <td>-0.003835</td>\n",
       "      <td>-0.024525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBA13_KMH_211</th>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.004727</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>0.050484</td>\n",
       "      <td>0.127423</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>0.109367</td>\n",
       "      <td>-0.023419</td>\n",
       "      <td>0.126570</td>\n",
       "      <td>0.109568</td>\n",
       "      <td>0.960155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>-0.022973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KBA13_HERST_SONST</th>\n",
       "      <td>-0.069172</td>\n",
       "      <td>-0.058545</td>\n",
       "      <td>-0.106164</td>\n",
       "      <td>-0.104668</td>\n",
       "      <td>-0.169633</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>-0.167843</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>-0.014234</td>\n",
       "      <td>-0.012642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059229</td>\n",
       "      <td>0.063293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP_FAMILIE_FEIN</th>\n",
       "      <td>0.942819</td>\n",
       "      <td>0.984100</td>\n",
       "      <td>0.236180</td>\n",
       "      <td>0.241076</td>\n",
       "      <td>0.107839</td>\n",
       "      <td>0.917662</td>\n",
       "      <td>-0.059229</td>\n",
       "      <td>-0.047557</td>\n",
       "      <td>-0.125571</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>-0.045396</td>\n",
       "      <td>-0.003835</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>-0.059229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <td>-0.177903</td>\n",
       "      <td>-0.131622</td>\n",
       "      <td>-0.367039</td>\n",
       "      <td>-0.351731</td>\n",
       "      <td>-0.286385</td>\n",
       "      <td>-0.200118</td>\n",
       "      <td>0.063293</td>\n",
       "      <td>0.092390</td>\n",
       "      <td>0.976900</td>\n",
       "      <td>-0.285719</td>\n",
       "      <td>0.084674</td>\n",
       "      <td>-0.024525</td>\n",
       "      <td>-0.022973</td>\n",
       "      <td>0.063293</td>\n",
       "      <td>-0.127050</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            LP_LEBENSPHASE_GROB  LP_FAMILIE_GROB  \\\n",
       "LP_LEBENSPHASE_GROB                    1.000000         0.957661   \n",
       "LP_FAMILIE_GROB                        0.957661         1.000000   \n",
       "LP_STATUS_FEIN                         0.390511         0.234589   \n",
       "LP_STATUS_GROB                         0.407881         0.245960   \n",
       "KBA13_GBZ                              0.153845         0.109975   \n",
       "LP_LEBENSPHASE_FEIN                    0.989961         0.941647   \n",
       "KBA13_FAB_SONSTIGE                    -0.069172        -0.058545   \n",
       "KBA13_HHZ                             -0.069047        -0.048613   \n",
       "ANZ_HAUSHALTE_AKTIV                   -0.177847        -0.129295   \n",
       "PLZ8_GBZ                               0.152153         0.108347   \n",
       "PLZ8_HHZ                              -0.064933        -0.046411   \n",
       "KBA13_KMH_250                         -0.000401        -0.004564   \n",
       "KBA13_KMH_211                         -0.000817        -0.004727   \n",
       "KBA13_HERST_SONST                     -0.069172        -0.058545   \n",
       "LP_FAMILIE_FEIN                        0.942819         0.984100   \n",
       "ANZ_STATISTISCHE_HAUSHALTE            -0.177903        -0.131622   \n",
       "\n",
       "                            LP_STATUS_FEIN  LP_STATUS_GROB  KBA13_GBZ  \\\n",
       "LP_LEBENSPHASE_GROB               0.390511        0.407881   0.153845   \n",
       "LP_FAMILIE_GROB                   0.234589        0.245960   0.109975   \n",
       "LP_STATUS_FEIN                    1.000000        0.982411   0.358554   \n",
       "LP_STATUS_GROB                    0.982411        1.000000   0.346147   \n",
       "KBA13_GBZ                         0.358554        0.346147   1.000000   \n",
       "LP_LEBENSPHASE_FEIN               0.443415        0.463909   0.178266   \n",
       "KBA13_FAB_SONSTIGE               -0.106164       -0.104668  -0.169633   \n",
       "KBA13_HHZ                        -0.122229       -0.107028   0.475506   \n",
       "ANZ_HAUSHALTE_AKTIV              -0.372640       -0.357599  -0.292483   \n",
       "PLZ8_GBZ                          0.356850        0.344592   0.979854   \n",
       "PLZ8_HHZ                         -0.109888       -0.095378   0.489083   \n",
       "KBA13_KMH_250                     0.038974        0.051409   0.127471   \n",
       "KBA13_KMH_211                     0.037655        0.050484   0.127423   \n",
       "KBA13_HERST_SONST                -0.106164       -0.104668  -0.169633   \n",
       "LP_FAMILIE_FEIN                   0.236180        0.241076   0.107839   \n",
       "ANZ_STATISTISCHE_HAUSHALTE       -0.367039       -0.351731  -0.286385   \n",
       "\n",
       "                            LP_LEBENSPHASE_FEIN  KBA13_FAB_SONSTIGE  \\\n",
       "LP_LEBENSPHASE_GROB                    0.989961           -0.069172   \n",
       "LP_FAMILIE_GROB                        0.941647           -0.058545   \n",
       "LP_STATUS_FEIN                         0.443415           -0.106164   \n",
       "LP_STATUS_GROB                         0.463909           -0.104668   \n",
       "KBA13_GBZ                              0.178266           -0.169633   \n",
       "LP_LEBENSPHASE_FEIN                    1.000000           -0.074396   \n",
       "KBA13_FAB_SONSTIGE                    -0.074396            1.000000   \n",
       "KBA13_HHZ                             -0.074577            0.018634   \n",
       "ANZ_HAUSHALTE_AKTIV                   -0.201056            0.063624   \n",
       "PLZ8_GBZ                               0.176442           -0.167843   \n",
       "PLZ8_HHZ                              -0.069709            0.023256   \n",
       "KBA13_KMH_250                          0.004134           -0.014234   \n",
       "KBA13_KMH_211                          0.003681           -0.012642   \n",
       "KBA13_HERST_SONST                     -0.074396            1.000000   \n",
       "LP_FAMILIE_FEIN                        0.917662           -0.059229   \n",
       "ANZ_STATISTISCHE_HAUSHALTE            -0.200118            0.063293   \n",
       "\n",
       "                            KBA13_HHZ  ANZ_HAUSHALTE_AKTIV  PLZ8_GBZ  \\\n",
       "LP_LEBENSPHASE_GROB         -0.069047            -0.177847  0.152153   \n",
       "LP_FAMILIE_GROB             -0.048613            -0.129295  0.108347   \n",
       "LP_STATUS_FEIN              -0.122229            -0.372640  0.356850   \n",
       "LP_STATUS_GROB              -0.107028            -0.357599  0.344592   \n",
       "KBA13_GBZ                    0.475506            -0.292483  0.979854   \n",
       "LP_LEBENSPHASE_FEIN         -0.074577            -0.201056  0.176442   \n",
       "KBA13_FAB_SONSTIGE           0.018634             0.063624 -0.167843   \n",
       "KBA13_HHZ                    1.000000             0.094123  0.475023   \n",
       "ANZ_HAUSHALTE_AKTIV          0.094123             1.000000 -0.291662   \n",
       "PLZ8_GBZ                     0.475023            -0.291662  1.000000   \n",
       "PLZ8_HHZ                     0.968725             0.086214  0.497958   \n",
       "KBA13_KMH_250                0.106656            -0.024765  0.126185   \n",
       "KBA13_KMH_211                0.109367            -0.023419  0.126570   \n",
       "KBA13_HERST_SONST            0.018634             0.063624 -0.167843   \n",
       "LP_FAMILIE_FEIN             -0.047557            -0.125571  0.106649   \n",
       "ANZ_STATISTISCHE_HAUSHALTE   0.092390             0.976900 -0.285719   \n",
       "\n",
       "                            PLZ8_HHZ  KBA13_KMH_250  KBA13_KMH_211  \\\n",
       "LP_LEBENSPHASE_GROB        -0.064933      -0.000401      -0.000817   \n",
       "LP_FAMILIE_GROB            -0.046411      -0.004564      -0.004727   \n",
       "LP_STATUS_FEIN             -0.109888       0.038974       0.037655   \n",
       "LP_STATUS_GROB             -0.095378       0.051409       0.050484   \n",
       "KBA13_GBZ                   0.489083       0.127471       0.127423   \n",
       "LP_LEBENSPHASE_FEIN        -0.069709       0.004134       0.003681   \n",
       "KBA13_FAB_SONSTIGE          0.023256      -0.014234      -0.012642   \n",
       "KBA13_HHZ                   0.968725       0.106656       0.109367   \n",
       "ANZ_HAUSHALTE_AKTIV         0.086214      -0.024765      -0.023419   \n",
       "PLZ8_GBZ                    0.497958       0.126185       0.126570   \n",
       "PLZ8_HHZ                    1.000000       0.106652       0.109568   \n",
       "KBA13_KMH_250               0.106652       1.000000       0.960155   \n",
       "KBA13_KMH_211               0.109568       0.960155       1.000000   \n",
       "KBA13_HERST_SONST           0.023256      -0.014234      -0.012642   \n",
       "LP_FAMILIE_FEIN            -0.045396      -0.003835      -0.003986   \n",
       "ANZ_STATISTISCHE_HAUSHALTE  0.084674      -0.024525      -0.022973   \n",
       "\n",
       "                            KBA13_HERST_SONST  LP_FAMILIE_FEIN  \\\n",
       "LP_LEBENSPHASE_GROB                 -0.069172         0.942819   \n",
       "LP_FAMILIE_GROB                     -0.058545         0.984100   \n",
       "LP_STATUS_FEIN                      -0.106164         0.236180   \n",
       "LP_STATUS_GROB                      -0.104668         0.241076   \n",
       "KBA13_GBZ                           -0.169633         0.107839   \n",
       "LP_LEBENSPHASE_FEIN                 -0.074396         0.917662   \n",
       "KBA13_FAB_SONSTIGE                   1.000000        -0.059229   \n",
       "KBA13_HHZ                            0.018634        -0.047557   \n",
       "ANZ_HAUSHALTE_AKTIV                  0.063624        -0.125571   \n",
       "PLZ8_GBZ                            -0.167843         0.106649   \n",
       "PLZ8_HHZ                             0.023256        -0.045396   \n",
       "KBA13_KMH_250                       -0.014234        -0.003835   \n",
       "KBA13_KMH_211                       -0.012642        -0.003986   \n",
       "KBA13_HERST_SONST                    1.000000        -0.059229   \n",
       "LP_FAMILIE_FEIN                     -0.059229         1.000000   \n",
       "ANZ_STATISTISCHE_HAUSHALTE           0.063293        -0.127050   \n",
       "\n",
       "                            ANZ_STATISTISCHE_HAUSHALTE  \n",
       "LP_LEBENSPHASE_GROB                          -0.177903  \n",
       "LP_FAMILIE_GROB                              -0.131622  \n",
       "LP_STATUS_FEIN                               -0.367039  \n",
       "LP_STATUS_GROB                               -0.351731  \n",
       "KBA13_GBZ                                    -0.286385  \n",
       "LP_LEBENSPHASE_FEIN                          -0.200118  \n",
       "KBA13_FAB_SONSTIGE                            0.063293  \n",
       "KBA13_HHZ                                     0.092390  \n",
       "ANZ_HAUSHALTE_AKTIV                           0.976900  \n",
       "PLZ8_GBZ                                     -0.285719  \n",
       "PLZ8_HHZ                                      0.084674  \n",
       "KBA13_KMH_250                                -0.024525  \n",
       "KBA13_KMH_211                                -0.022973  \n",
       "KBA13_HERST_SONST                             0.063293  \n",
       "LP_FAMILIE_FEIN                              -0.127050  \n",
       "ANZ_STATISTISCHE_HAUSHALTE                    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = azdias.corr()\n",
    "high_corr = corr_df.applymap(lambda x: abs(x) > 0.96)\n",
    "a_list = high_corr.sum().sort_values()\n",
    "high_corr_list = a_list[a_list > 1]\n",
    "corr_df.loc[high_corr_list.index, high_corr_list.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to clean and preprocess datasets\n",
    "\n",
    "drop_cols = ['LNR', 'KK_KUNDENTYP', 'ALTER_KIND1', 'ALTER_KIND2', 'ALTER_KIND3', 'ALTER_KIND4', 'EXTSEL992', \n",
    "'CAMEO_DEU_2015', 'CAMEO_DEUG_2015', 'CAMEO_INTL_2015', 'D19_LETZTER_KAUF_BRANCHE', 'EINGEZOGENAM_HH_JAHR', \n",
    "'EINGEFUEGT_AM', 'ALTERSKATEGORIE_FEIN', 'D19_WEIN_FEINKOST', 'PRAEGENDE_JUGENDJAHRE', 'EINGEFUEGT_AM',  \n",
    "'D19_VERSAND_ONLINE_DATUM', 'D19_VERSAND_DATUM', 'LP_FAMILIE_FEIN', 'LP_LEBENSPHASE_FEIN', 'LP_STATUS_FEIN',\n",
    "'ANZ_STATISTISCHE_HAUSHALTE', 'D19_VERSAND_ANZ_24']\n",
    "\n",
    "def clean_dataset(df):\n",
    "    df.dropna(thresh=335, inplace=True)\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "    return(df)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Replace east and west chars with numbers\n",
    "    #df.loc[:, 'OST_WEST_KZ'].replace({'W':0, 'O':1}, inplace=True);\n",
    "\n",
    "    imp = SimpleImputer(missing_values=float(\"NaN\"), strategy=\"most_frequent\", copy = False)\n",
    "    processed_df = imp.fit_transform(df)\n",
    "    \n",
    "    s_scaler = StandardScaler()\n",
    "    processed_df = pd.DataFrame(s_scaler.fit_transform(processed_df))\n",
    "    processed_df.columns = df.columns\n",
    "    \n",
    "    return(pd.DataFrame(processed_df ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891221 entries, 0 to 891220\n",
      "Columns: 366 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(93), object(6)\n",
      "memory usage: 2.4+ GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 750604 entries, 1 to 891220\n",
      "Columns: 343 entries, AGER_TYP to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(255), int64(87), object(1)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "azdias.info()\n",
    "clean_dataset(azdias)\n",
    "azdias.info()\n",
    "azdias.to_csv('arvato_data/AZDIAS_dropped.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_preprocessed  = preprocess_data(azdias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "customers = pd.read_csv('arvato_data/Udacity_CUSTOMERS_052018.csv',  dtype={18:'str',19:'str'}, sep=';')\n",
    "# Drop the extra column of customers dataset.\n",
    "customers.drop(columns=['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191652, 366)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 191652 entries, 0 to 191651\n",
      "Columns: 366 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(93), object(6)\n",
      "memory usage: 535.2+ MB\n",
      "None\n",
      "                 LNR       AGER_TYP     AKT_DAT_KL       ALTER_HH  \\\n",
      "count  191652.000000  191652.000000  145056.000000  145056.000000   \n",
      "mean    95826.500000       0.344359       1.747525      11.352009   \n",
      "std     55325.311233       1.391672       1.966334       6.275026   \n",
      "min         1.000000      -1.000000       1.000000       0.000000   \n",
      "25%     47913.750000      -1.000000       1.000000       8.000000   \n",
      "50%     95826.500000       0.000000       1.000000      11.000000   \n",
      "75%    143739.250000       2.000000       1.000000      16.000000   \n",
      "max    191652.000000       3.000000       9.000000      21.000000   \n",
      "\n",
      "        ALTER_KIND1  ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  \\\n",
      "count  11766.000000  5100.000000  1275.000000   236.000000   \n",
      "mean      12.337243    13.672353    14.647059    15.377119   \n",
      "std        4.006050     3.243335     2.753787     2.307653   \n",
      "min        2.000000     2.000000     5.000000     8.000000   \n",
      "25%        9.000000    11.000000    13.000000    14.000000   \n",
      "50%       13.000000    14.000000    15.000000    16.000000   \n",
      "75%       16.000000    16.000000    17.000000    17.000000   \n",
      "max       18.000000    18.000000    18.000000    18.000000   \n",
      "\n",
      "       ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...            VHN  \\\n",
      "count         139810.000000        141725.000000  ...  137392.000000   \n",
      "mean              10.331579             4.965863  ...       2.429508   \n",
      "std                4.134828            14.309694  ...       1.148821   \n",
      "min                0.000000             0.000000  ...       0.000000   \n",
      "25%                9.000000             1.000000  ...       2.000000   \n",
      "50%               10.000000             1.000000  ...       2.000000   \n",
      "75%               13.000000             4.000000  ...       3.000000   \n",
      "max               25.000000           523.000000  ...       4.000000   \n",
      "\n",
      "            VK_DHT4A     VK_DISTANZ        VK_ZG11  W_KEIT_KIND_HH  \\\n",
      "count  143781.000000  143781.000000  143781.000000   137910.000000   \n",
      "mean        4.374417       4.564769       3.168868        4.152716   \n",
      "std         2.924355       2.887035       2.233516        1.974375   \n",
      "min         1.000000       1.000000       1.000000        0.000000   \n",
      "25%         2.000000       2.000000       1.000000        2.000000   \n",
      "50%         4.000000       4.000000       3.000000        5.000000   \n",
      "75%         7.000000       7.000000       4.000000        6.000000   \n",
      "max        11.000000      13.000000      11.000000        6.000000   \n",
      "\n",
      "       WOHNDAUER_2008       WOHNLAGE       ZABEOTYP      ANREDE_KZ  \\\n",
      "count   145056.000000  141725.000000  191652.000000  191652.000000   \n",
      "mean         8.646371       3.723133       2.576806       1.376432   \n",
      "std          1.154001       2.095540       1.168486       0.484492   \n",
      "min          1.000000       0.000000       1.000000       1.000000   \n",
      "25%          9.000000       2.000000       1.000000       1.000000   \n",
      "50%          9.000000       3.000000       3.000000       1.000000   \n",
      "75%          9.000000       5.000000       3.000000       2.000000   \n",
      "max          9.000000       8.000000       6.000000       2.000000   \n",
      "\n",
      "       ALTERSKATEGORIE_GROB  \n",
      "count         191652.000000  \n",
      "mean               3.060907  \n",
      "std                1.086254  \n",
      "min                1.000000  \n",
      "25%                3.000000  \n",
      "50%                3.000000  \n",
      "75%                4.000000  \n",
      "max                9.000000  \n",
      "\n",
      "[8 rows x 360 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(customers.shape)\n",
    "print(customers.info())\n",
    "print(customers.describe())\n",
    "customers_missing_rows = customers.isna().mean(axis=1).round(4) * 100\n",
    "customers_missing_rows.sort_values(inplace=True)\n",
    "customers_missing_rows[customers_missing_rows > 80.0 ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49930\n"
     ]
    }
   ],
   "source": [
    "customers.head()\n",
    "customers_missing_rows = customers.isna().mean(axis=1).round(4) * 100\n",
    "customers_missing_rows.sort_values(inplace=True)\n",
    "print(customers_missing_rows[customers_missing_rows > 60.0 ].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 135051 entries, 0 to 191651\n",
      "Columns: 343 entries, AGER_TYP to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(255), int64(88)\n",
      "memory usage: 354.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135051 entries, 0 to 135050\n",
      "Columns: 343 entries, AGER_TYP to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(343)\n",
      "memory usage: 353.4 MB\n",
      "None\n",
      "   AGER_TYP  AKT_DAT_KL  ALTER_HH  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
      "0  0.914267   -0.369655 -0.212081            -0.281147     -0.127196   \n",
      "1 -1.360120   -0.369655 -0.850827            -0.281147     -0.127196   \n",
      "2  0.156138   -0.369655 -0.531454            -0.352841     -0.127196   \n",
      "3 -1.360120   -0.369655  1.384786             0.149018     -0.127196   \n",
      "4  0.156138   -0.369655 -0.052394            -0.281147     -0.127196   \n",
      "\n",
      "   ANZ_KINDER  ANZ_PERSONEN  ANZ_TITEL    ARBEIT  BALLRAUM  ...       VHN  \\\n",
      "0   -0.264751     -0.202478  -0.134442 -1.817040 -0.611956  ...  0.502318   \n",
      "1   -0.264751     -0.916295  -0.134442  0.166624  1.277512  ...  1.378005   \n",
      "2   -0.264751     -1.630112  -0.134442 -1.817040  1.277512  ... -0.373368   \n",
      "3   -0.264751      1.225156  -0.134442  0.166624 -0.611956  ...  1.378005   \n",
      "4   -0.264751     -0.202478  -0.134442  0.166624  1.277512  ...  1.378005   \n",
      "\n",
      "   VK_DHT4A  VK_DISTANZ   VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
      "0  0.223609   -0.518992 -0.498829        0.871836        0.278574  1.584820   \n",
      "1  1.925671    2.941938  3.566436        0.871836        0.278574 -0.837562   \n",
      "2  0.564022   -0.172899 -0.498829        0.871836        0.278574  1.584820   \n",
      "3 -0.457215    0.173194  0.404563       -1.245470        0.278574 -0.353086   \n",
      "4 -1.138040   -0.865085 -0.950525        0.871836        0.278574 -1.322039   \n",
      "\n",
      "   ZABEOTYP  ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
      "0  0.457019  -0.701918              0.650473  \n",
      "1  0.457019   1.424668              0.650473  \n",
      "2 -1.075715  -0.701918              0.650473  \n",
      "3 -1.075715  -0.701918             -0.671131  \n",
      "4 -0.309348  -0.701918             -0.671131  \n",
      "\n",
      "[5 rows x 343 columns]\n"
     ]
    }
   ],
   "source": [
    "customers.info()\n",
    "clean_dataset(customers)\n",
    "customers_preprocessed = preprocess_data(customers)\n",
    "print(customers_preprocessed.info())\n",
    "print(customers_preprocessed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750604 entries, 0 to 750603\n",
      "Columns: 343 entries, AGER_TYP to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(343)\n",
      "memory usage: 1.9 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#azdias = pd.read_csv('arvato_data/AZDIAS_dropped.csv',  sep=';', index_col=0)\n",
    "azdias_preprocessed = pd.read_csv('arvato_data/AZDIAS_cleaned.csv', sep=';')\n",
    "azdias_preprocessed.drop(azdias_preprocessed.columns[0], axis=1, inplace=True)\n",
    "print(azdias_preprocessed.info())\n",
    "print(azdias_preprocessed.describe())\n",
    "print(azdias_preprocessed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>-1.417136</td>\n",
       "      <td>0.159141</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>0.233213</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367375</td>\n",
       "      <td>0.681651</td>\n",
       "      <td>1.055463</td>\n",
       "      <td>1.452298</td>\n",
       "      <td>-0.601795</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>1.139257</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>-1.684810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.095291</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>1.031493</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>-0.601795</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>-1.085614</td>\n",
       "      <td>1.139257</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857962</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>0.285529</td>\n",
       "      <td>-0.479357</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-1.487017</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-1.195149</td>\n",
       "      <td>-0.061918</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.086056</td>\n",
       "      <td>0.331809</td>\n",
       "      <td>0.748360</td>\n",
       "      <td>1.810842</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>1.557051</td>\n",
       "      <td>-0.284771</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>1.088562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>1.202349</td>\n",
       "      <td>-0.351657</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>1.953443</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>-1.067560</td>\n",
       "      <td>-0.787153</td>\n",
       "      <td>-0.698965</td>\n",
       "      <td>-1.129672</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>-0.557081</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.668276</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>-0.107394</td>\n",
       "      <td>-0.223958</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-1.195149</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>1.381336</td>\n",
       "      <td>-0.172947</td>\n",
       "      <td>-0.698965</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>1.557051</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>-1.684810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750599</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>0.153446</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.414540</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>-0.717718</td>\n",
       "      <td>-0.172947</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>-0.601795</td>\n",
       "      <td>-2.097491</td>\n",
       "      <td>-0.557081</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750600</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>0.678452</td>\n",
       "      <td>0.159141</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>1.308238</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367375</td>\n",
       "      <td>-0.018033</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>0.499985</td>\n",
       "      <td>1.851272</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>-0.760353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750601</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>-0.351657</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-1.487017</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-1.195149</td>\n",
       "      <td>0.394801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>0.331809</td>\n",
       "      <td>0.748360</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>-1.568300</td>\n",
       "      <td>1.557051</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>-0.760353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750602</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>-1.417136</td>\n",
       "      <td>-0.096258</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>1.763484</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367375</td>\n",
       "      <td>1.031493</td>\n",
       "      <td>0.134155</td>\n",
       "      <td>-0.340421</td>\n",
       "      <td>-1.657550</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>0.499985</td>\n",
       "      <td>1.139257</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>-1.684810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750603</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>-1.417136</td>\n",
       "      <td>0.095291</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504017</td>\n",
       "      <td>0.681651</td>\n",
       "      <td>0.748360</td>\n",
       "      <td>0.376666</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>-2.626681</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.284771</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>1.088562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750604 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGER_TYP  AKT_DAT_KL  ALTER_HH  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
       "0      -0.572979    1.249407 -1.417136             0.159141     -0.128334   \n",
       "1      -0.572979    1.249407  0.809426             0.095291     -0.128334   \n",
       "2       1.857962   -0.942516  0.285529            -0.479357     -0.128334   \n",
       "3      -0.572979   -0.942516  1.202349            -0.351657     -0.128334   \n",
       "4       2.668276   -0.942516 -0.107394            -0.223958     -0.128334   \n",
       "...          ...         ...       ...                  ...           ...   \n",
       "750599 -0.572979    0.153446  0.809426             0.414540     -0.128334   \n",
       "750600 -0.572979    1.249407  0.678452             0.159141     -0.128334   \n",
       "750601 -0.572979   -0.942516  0.809426            -0.351657     -0.128334   \n",
       "750602 -0.572979    1.249407 -1.417136            -0.096258     -0.128334   \n",
       "750603 -0.572979   -0.942516 -1.417136             0.095291     -0.128334   \n",
       "\n",
       "        ANZ_KINDER  ANZ_PERSONEN  ANZ_TITEL    ARBEIT  BALLRAUM  ...  \\\n",
       "0        -0.296889      0.233213  -0.060628 -0.190359  0.851519  ...   \n",
       "1        -0.296889     -0.626902  -0.060628 -0.190359 -0.975355  ...   \n",
       "2        -0.296889     -1.487017  -0.060628 -1.195149 -0.061918  ...   \n",
       "3        -0.296889      1.953443  -0.060628  0.814431 -0.975355  ...   \n",
       "4        -0.296889     -0.626902  -0.060628 -1.195149  0.851519  ...   \n",
       "...            ...           ...        ...       ...       ...  ...   \n",
       "750599   -0.296889     -0.626902  -0.060628  0.814431  0.851519  ...   \n",
       "750600   -0.296889     -0.626902  -0.060628  0.814431  1.308238  ...   \n",
       "750601   -0.296889     -1.487017  -0.060628 -1.195149  0.394801  ...   \n",
       "750602    1.763484     -0.626902  -0.060628  0.814431 -0.975355  ...   \n",
       "750603   -0.296889     -0.626902  -0.060628 -0.190359  0.851519  ...   \n",
       "\n",
       "             VHN  VK_DHT4A  VK_DISTANZ   VK_ZG11  W_KEIT_KIND_HH  \\\n",
       "0       1.367375  0.681651    1.055463  1.452298       -0.601795   \n",
       "1      -0.359341  1.031493    0.441258  0.018122       -0.601795   \n",
       "2      -2.086056  0.331809    0.748360  1.810842        0.981839   \n",
       "3      -0.359341 -1.067560   -0.787153 -0.698965       -1.129672   \n",
       "4      -0.359341  1.381336   -0.172947 -0.698965        0.981839   \n",
       "...          ...       ...         ...       ...             ...   \n",
       "750599 -0.359341 -0.717718   -0.172947  0.735210       -0.601795   \n",
       "750600  1.367375 -0.018033    0.441258  0.018122        0.981839   \n",
       "750601 -0.359341  0.331809    0.748360  0.735210        0.981839   \n",
       "750602  1.367375  1.031493    0.134155 -0.340421       -1.657550   \n",
       "750603  0.504017  0.681651    0.748360  0.376666        0.981839   \n",
       "\n",
       "        WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "0             0.548461 -0.028548  1.139257   0.957594             -1.684810  \n",
       "1             0.548461 -1.085614  1.139257   0.957594              0.164104  \n",
       "2             0.548461  1.557051 -0.284771   0.957594              1.088562  \n",
       "3             0.548461 -0.557081  0.427243  -1.044283              0.164104  \n",
       "4             0.548461  1.557051  0.427243   0.957594             -1.684810  \n",
       "...                ...       ...       ...        ...                   ...  \n",
       "750599       -2.097491 -0.557081  0.427243   0.957594              0.164104  \n",
       "750600        0.548461  0.499985  1.851272  -1.044283             -0.760353  \n",
       "750601       -1.568300  1.557051  0.427243   0.957594             -0.760353  \n",
       "750602        0.548461  0.499985  1.139257  -1.044283             -1.684810  \n",
       "750603       -2.626681 -0.028548 -0.284771  -1.044283              1.088562  \n",
       "\n",
       "[750604 rows x 343 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scree_plot(pca):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    num_components = len(pca.explained_variance_ratio_)\n",
    "    ind = np.arange(num_components)\n",
    "    vals = pca.explained_variance_ratio_\n",
    "    \n",
    "    plt.figure(figsize=(14,8))\n",
    "    ax = plt.subplot(111)\n",
    "    plt.style.use(\"ggplot\")\n",
    "    \n",
    "    cumvals = np.cumsum(vals)\n",
    "    ax.bar(ind, vals,color='teal')\n",
    "    \n",
    "    ax.annotate(r\"%s%%\" % ((str(vals[0]*100)[:4])), (ind[0]+0.2,vals[0]), va='bottom',ha='center',fontsize=12)\n",
    "        \n",
    "    ax.xaxis.set_tick_params(width=0)\n",
    "    ax.yaxis.set_tick_params(width=1,length=12)\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(np.cumsum(pca.explained_variance_ratio_), label='Cumulative Variance',linewidth=2, color = 'red');\n",
    "    \n",
    "    n_components = min(np.where(np.cumsum(pca.explained_variance_ratio_)>0.85)[0]+1)\n",
    "    ax2.axhline(np.cumsum(pca.explained_variance_ratio_)[n_components], linestyle='dashed', color='black')\n",
    "    \n",
    "    ax.set_xlabel(\"Principal Component\",fontsize=13)\n",
    "    ax.set_ylabel(\"Variance Explained (%)\",fontsize=13)\n",
    "    plt.title(\"Explained Variance for 140 Components - {}\".format(cumvals[-1]),fontsize=15)\n",
    "    #ax.set_title('n_components needed for >%60 explained variance: {}'.format(n_components));\n",
    "    \n",
    "#    plt.show()\n",
    "    plt.savefig('PCA_Variances')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>-1.417136</td>\n",
       "      <td>0.159141</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>0.233213</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367375</td>\n",
       "      <td>0.681651</td>\n",
       "      <td>1.055463</td>\n",
       "      <td>1.452298</td>\n",
       "      <td>-0.601795</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>1.139257</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>-1.684810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.095291</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>1.031493</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>-0.601795</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>-1.085614</td>\n",
       "      <td>1.139257</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857962</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>0.285529</td>\n",
       "      <td>-0.479357</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-1.487017</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-1.195149</td>\n",
       "      <td>-0.061918</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.086056</td>\n",
       "      <td>0.331809</td>\n",
       "      <td>0.748360</td>\n",
       "      <td>1.810842</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>1.557051</td>\n",
       "      <td>-0.284771</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>1.088562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>1.202349</td>\n",
       "      <td>-0.351657</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>1.953443</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>-1.067560</td>\n",
       "      <td>-0.787153</td>\n",
       "      <td>-0.698965</td>\n",
       "      <td>-1.129672</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>-0.557081</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.668276</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>-0.107394</td>\n",
       "      <td>-0.223958</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-1.195149</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>1.381336</td>\n",
       "      <td>-0.172947</td>\n",
       "      <td>-0.698965</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>1.557051</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>-1.684810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750599</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>0.153446</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.414540</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>-0.717718</td>\n",
       "      <td>-0.172947</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>-0.601795</td>\n",
       "      <td>-2.097491</td>\n",
       "      <td>-0.557081</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750600</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>0.678452</td>\n",
       "      <td>0.159141</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>1.308238</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367375</td>\n",
       "      <td>-0.018033</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>0.499985</td>\n",
       "      <td>1.851272</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>-0.760353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750601</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>-0.351657</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-1.487017</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-1.195149</td>\n",
       "      <td>0.394801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359341</td>\n",
       "      <td>0.331809</td>\n",
       "      <td>0.748360</td>\n",
       "      <td>0.735210</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>-1.568300</td>\n",
       "      <td>1.557051</td>\n",
       "      <td>0.427243</td>\n",
       "      <td>0.957594</td>\n",
       "      <td>-0.760353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750602</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>1.249407</td>\n",
       "      <td>-1.417136</td>\n",
       "      <td>-0.096258</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>1.763484</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>-0.975355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367375</td>\n",
       "      <td>1.031493</td>\n",
       "      <td>0.134155</td>\n",
       "      <td>-0.340421</td>\n",
       "      <td>-1.657550</td>\n",
       "      <td>0.548461</td>\n",
       "      <td>0.499985</td>\n",
       "      <td>1.139257</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>-1.684810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750603</th>\n",
       "      <td>-0.572979</td>\n",
       "      <td>-0.942516</td>\n",
       "      <td>-1.417136</td>\n",
       "      <td>0.095291</td>\n",
       "      <td>-0.128334</td>\n",
       "      <td>-0.296889</td>\n",
       "      <td>-0.626902</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>-0.190359</td>\n",
       "      <td>0.851519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504017</td>\n",
       "      <td>0.681651</td>\n",
       "      <td>0.748360</td>\n",
       "      <td>0.376666</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>-2.626681</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>-0.284771</td>\n",
       "      <td>-1.044283</td>\n",
       "      <td>1.088562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750604 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGER_TYP  AKT_DAT_KL  ALTER_HH  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
       "0      -0.572979    1.249407 -1.417136             0.159141     -0.128334   \n",
       "1      -0.572979    1.249407  0.809426             0.095291     -0.128334   \n",
       "2       1.857962   -0.942516  0.285529            -0.479357     -0.128334   \n",
       "3      -0.572979   -0.942516  1.202349            -0.351657     -0.128334   \n",
       "4       2.668276   -0.942516 -0.107394            -0.223958     -0.128334   \n",
       "...          ...         ...       ...                  ...           ...   \n",
       "750599 -0.572979    0.153446  0.809426             0.414540     -0.128334   \n",
       "750600 -0.572979    1.249407  0.678452             0.159141     -0.128334   \n",
       "750601 -0.572979   -0.942516  0.809426            -0.351657     -0.128334   \n",
       "750602 -0.572979    1.249407 -1.417136            -0.096258     -0.128334   \n",
       "750603 -0.572979   -0.942516 -1.417136             0.095291     -0.128334   \n",
       "\n",
       "        ANZ_KINDER  ANZ_PERSONEN  ANZ_TITEL    ARBEIT  BALLRAUM  ...  \\\n",
       "0        -0.296889      0.233213  -0.060628 -0.190359  0.851519  ...   \n",
       "1        -0.296889     -0.626902  -0.060628 -0.190359 -0.975355  ...   \n",
       "2        -0.296889     -1.487017  -0.060628 -1.195149 -0.061918  ...   \n",
       "3        -0.296889      1.953443  -0.060628  0.814431 -0.975355  ...   \n",
       "4        -0.296889     -0.626902  -0.060628 -1.195149  0.851519  ...   \n",
       "...            ...           ...        ...       ...       ...  ...   \n",
       "750599   -0.296889     -0.626902  -0.060628  0.814431  0.851519  ...   \n",
       "750600   -0.296889     -0.626902  -0.060628  0.814431  1.308238  ...   \n",
       "750601   -0.296889     -1.487017  -0.060628 -1.195149  0.394801  ...   \n",
       "750602    1.763484     -0.626902  -0.060628  0.814431 -0.975355  ...   \n",
       "750603   -0.296889     -0.626902  -0.060628 -0.190359  0.851519  ...   \n",
       "\n",
       "             VHN  VK_DHT4A  VK_DISTANZ   VK_ZG11  W_KEIT_KIND_HH  \\\n",
       "0       1.367375  0.681651    1.055463  1.452298       -0.601795   \n",
       "1      -0.359341  1.031493    0.441258  0.018122       -0.601795   \n",
       "2      -2.086056  0.331809    0.748360  1.810842        0.981839   \n",
       "3      -0.359341 -1.067560   -0.787153 -0.698965       -1.129672   \n",
       "4      -0.359341  1.381336   -0.172947 -0.698965        0.981839   \n",
       "...          ...       ...         ...       ...             ...   \n",
       "750599 -0.359341 -0.717718   -0.172947  0.735210       -0.601795   \n",
       "750600  1.367375 -0.018033    0.441258  0.018122        0.981839   \n",
       "750601 -0.359341  0.331809    0.748360  0.735210        0.981839   \n",
       "750602  1.367375  1.031493    0.134155 -0.340421       -1.657550   \n",
       "750603  0.504017  0.681651    0.748360  0.376666        0.981839   \n",
       "\n",
       "        WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "0             0.548461 -0.028548  1.139257   0.957594             -1.684810  \n",
       "1             0.548461 -1.085614  1.139257   0.957594              0.164104  \n",
       "2             0.548461  1.557051 -0.284771   0.957594              1.088562  \n",
       "3             0.548461 -0.557081  0.427243  -1.044283              0.164104  \n",
       "4             0.548461  1.557051  0.427243   0.957594             -1.684810  \n",
       "...                ...       ...       ...        ...                   ...  \n",
       "750599       -2.097491 -0.557081  0.427243   0.957594              0.164104  \n",
       "750600        0.548461  0.499985  1.851272  -1.044283             -0.760353  \n",
       "750601       -1.568300  1.557051  0.427243   0.957594             -0.760353  \n",
       "750602        0.548461  0.499985  1.139257  -1.044283             -1.684810  \n",
       "750603       -2.626681 -0.028548 -0.284771  -1.044283              1.088562  \n",
       "\n",
       "[750604 rows x 343 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Use PCA to reduce complexity of the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(140)\n",
    "df_pca = pca.fit_transform(azdias_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scree_plot(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2, s: 32107795.638559457\n",
      "i: 4, s: 28756856.173699785\n",
      "i: 6, s: 27532434.127998006\n",
      "i: 8, s: 26771138.79778634\n",
      "i: 10, s: 26212247.46915828\n",
      "i: 12, s: 25804769.57756966\n",
      "i: 14, s: 25468221.86747202\n",
      "i: 16, s: 25210328.93755425\n",
      "i: 18, s: 24997205.38342546\n",
      "i: 20, s: 24780420.427106295\n",
      "i: 22, s: 24549395.26688052\n",
      "i: 24, s: 24316974.036438864\n",
      "i: 26, s: 24142343.215039134\n",
      "Wall time: 24min 51s\n",
      "Parser   : 512 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def fetch_score(data, center):\n",
    "    kmeans = KMeans(n_clusters=center, random_state=42)\n",
    "    km_model = kmeans.fit(data)\n",
    "    score = abs(km_model.score(data))\n",
    "    return(score)\n",
    "\n",
    "\n",
    "scores = []\n",
    "for i in range(2, 28, 2):\n",
    "    s = fetch_score(df_pca_sub, i)\n",
    "    scores.append(s)\n",
    "    print('i: {}, s: {}'.format(i,s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "centers = [2,4,6,8,10,12,14,16,18,20,22,24,26]\n",
    "plt.plot(centers, scores, linestyle='-', marker='o', color='teal')\n",
    "plt.title('KMeans Centroids \\n', size=16 )\n",
    "plt.xlabel('# of Centroids ( K )')\n",
    "plt.ylabel('Scores')\n",
    "#plt.show()\n",
    "plt.savefig('kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120000, 140)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_pca_sub = df_pca[np.random.choice(df_pca.shape[0], 120000, replace=False),:]\n",
    "df_pca_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 9s\n",
      "Parser   : 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Re-fit and predict the k-means model with the selected 14 clusters\n",
    "kmeans = KMeans(n_clusters=14)\n",
    "pop_predict = kmeans.fit_predict(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.914267</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>-0.212081</td>\n",
       "      <td>-0.281147</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>-0.202478</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>-1.817040</td>\n",
       "      <td>-0.611956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502318</td>\n",
       "      <td>0.223609</td>\n",
       "      <td>-0.518992</td>\n",
       "      <td>-0.498829</td>\n",
       "      <td>0.871836</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>1.584820</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>0.650473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.360120</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>-0.850827</td>\n",
       "      <td>-0.281147</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>-0.916295</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>0.166624</td>\n",
       "      <td>1.277512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378005</td>\n",
       "      <td>1.925671</td>\n",
       "      <td>2.941938</td>\n",
       "      <td>3.566436</td>\n",
       "      <td>0.871836</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-0.837562</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>1.424668</td>\n",
       "      <td>0.650473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.156138</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>-0.531454</td>\n",
       "      <td>-0.352841</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>-1.630112</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>-1.817040</td>\n",
       "      <td>1.277512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373368</td>\n",
       "      <td>0.564022</td>\n",
       "      <td>-0.172899</td>\n",
       "      <td>-0.498829</td>\n",
       "      <td>0.871836</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>1.584820</td>\n",
       "      <td>-1.075715</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>0.650473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.360120</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>1.384786</td>\n",
       "      <td>0.149018</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>1.225156</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>0.166624</td>\n",
       "      <td>-0.611956</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378005</td>\n",
       "      <td>-0.457215</td>\n",
       "      <td>0.173194</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>-1.245470</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-0.353086</td>\n",
       "      <td>-1.075715</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>-0.671131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156138</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>-0.052394</td>\n",
       "      <td>-0.281147</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>-0.202478</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>0.166624</td>\n",
       "      <td>1.277512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378005</td>\n",
       "      <td>-1.138040</td>\n",
       "      <td>-0.865085</td>\n",
       "      <td>-0.950525</td>\n",
       "      <td>0.871836</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-1.322039</td>\n",
       "      <td>-0.309348</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>-0.671131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135046</th>\n",
       "      <td>0.156138</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>-0.371767</td>\n",
       "      <td>-0.281147</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>-0.916295</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>0.166624</td>\n",
       "      <td>-1.556690</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378005</td>\n",
       "      <td>1.244846</td>\n",
       "      <td>1.211473</td>\n",
       "      <td>0.856260</td>\n",
       "      <td>0.871836</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-1.322039</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>-0.671131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135047</th>\n",
       "      <td>-1.360120</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>-1.808947</td>\n",
       "      <td>-0.352841</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>-1.630112</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>-1.817040</td>\n",
       "      <td>0.805145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373368</td>\n",
       "      <td>1.925671</td>\n",
       "      <td>0.865380</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.871836</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-0.353086</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>1.424668</td>\n",
       "      <td>0.650473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135048</th>\n",
       "      <td>0.914267</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>-0.281147</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>0.511339</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>0.166624</td>\n",
       "      <td>1.277512</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.249055</td>\n",
       "      <td>1.244846</td>\n",
       "      <td>1.211473</td>\n",
       "      <td>0.856260</td>\n",
       "      <td>-0.716144</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-0.353086</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>0.650473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135049</th>\n",
       "      <td>1.672396</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>0.266979</td>\n",
       "      <td>-0.066065</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>1.225156</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>0.166624</td>\n",
       "      <td>-0.611956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502318</td>\n",
       "      <td>-1.138040</td>\n",
       "      <td>-1.211178</td>\n",
       "      <td>-0.950525</td>\n",
       "      <td>-0.186817</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>-0.837562</td>\n",
       "      <td>0.457019</td>\n",
       "      <td>1.424668</td>\n",
       "      <td>-0.671131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135050</th>\n",
       "      <td>1.672396</td>\n",
       "      <td>-0.369655</td>\n",
       "      <td>-1.808947</td>\n",
       "      <td>-0.281147</td>\n",
       "      <td>-0.127196</td>\n",
       "      <td>-0.264751</td>\n",
       "      <td>0.511339</td>\n",
       "      <td>-0.134442</td>\n",
       "      <td>-1.817040</td>\n",
       "      <td>-0.611956</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.249055</td>\n",
       "      <td>-1.138040</td>\n",
       "      <td>-1.211178</td>\n",
       "      <td>-0.950525</td>\n",
       "      <td>-0.716144</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>1.584820</td>\n",
       "      <td>-1.075715</td>\n",
       "      <td>-0.701918</td>\n",
       "      <td>-1.992736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135051 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGER_TYP  AKT_DAT_KL  ALTER_HH  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  \\\n",
       "0       0.914267   -0.369655 -0.212081            -0.281147     -0.127196   \n",
       "1      -1.360120   -0.369655 -0.850827            -0.281147     -0.127196   \n",
       "2       0.156138   -0.369655 -0.531454            -0.352841     -0.127196   \n",
       "3      -1.360120   -0.369655  1.384786             0.149018     -0.127196   \n",
       "4       0.156138   -0.369655 -0.052394            -0.281147     -0.127196   \n",
       "...          ...         ...       ...                  ...           ...   \n",
       "135046  0.156138   -0.369655 -0.371767            -0.281147     -0.127196   \n",
       "135047 -1.360120    0.150206 -1.808947            -0.352841     -0.127196   \n",
       "135048  0.914267   -0.369655  0.586353            -0.281147     -0.127196   \n",
       "135049  1.672396   -0.369655  0.266979            -0.066065     -0.127196   \n",
       "135050  1.672396   -0.369655 -1.808947            -0.281147     -0.127196   \n",
       "\n",
       "        ANZ_KINDER  ANZ_PERSONEN  ANZ_TITEL    ARBEIT  BALLRAUM  ...  \\\n",
       "0        -0.264751     -0.202478  -0.134442 -1.817040 -0.611956  ...   \n",
       "1        -0.264751     -0.916295  -0.134442  0.166624  1.277512  ...   \n",
       "2        -0.264751     -1.630112  -0.134442 -1.817040  1.277512  ...   \n",
       "3        -0.264751      1.225156  -0.134442  0.166624 -0.611956  ...   \n",
       "4        -0.264751     -0.202478  -0.134442  0.166624  1.277512  ...   \n",
       "...            ...           ...        ...       ...       ...  ...   \n",
       "135046   -0.264751     -0.916295  -0.134442  0.166624 -1.556690  ...   \n",
       "135047   -0.264751     -1.630112  -0.134442 -1.817040  0.805145  ...   \n",
       "135048   -0.264751      0.511339  -0.134442  0.166624  1.277512  ...   \n",
       "135049   -0.264751      1.225156  -0.134442  0.166624 -0.611956  ...   \n",
       "135050   -0.264751      0.511339  -0.134442 -1.817040 -0.611956  ...   \n",
       "\n",
       "             VHN  VK_DHT4A  VK_DISTANZ   VK_ZG11  W_KEIT_KIND_HH  \\\n",
       "0       0.502318  0.223609   -0.518992 -0.498829        0.871836   \n",
       "1       1.378005  1.925671    2.941938  3.566436        0.871836   \n",
       "2      -0.373368  0.564022   -0.172899 -0.498829        0.871836   \n",
       "3       1.378005 -0.457215    0.173194  0.404563       -1.245470   \n",
       "4       1.378005 -1.138040   -0.865085 -0.950525        0.871836   \n",
       "...          ...       ...         ...       ...             ...   \n",
       "135046  1.378005  1.244846    1.211473  0.856260        0.871836   \n",
       "135047 -0.373368  1.925671    0.865380  0.404563        0.871836   \n",
       "135048 -1.249055  1.244846    1.211473  0.856260       -0.716144   \n",
       "135049  0.502318 -1.138040   -1.211178 -0.950525       -0.186817   \n",
       "135050 -1.249055 -1.138040   -1.211178 -0.950525       -0.716144   \n",
       "\n",
       "        WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "0             0.278574  1.584820  0.457019  -0.701918              0.650473  \n",
       "1             0.278574 -0.837562  0.457019   1.424668              0.650473  \n",
       "2             0.278574  1.584820 -1.075715  -0.701918              0.650473  \n",
       "3             0.278574 -0.353086 -1.075715  -0.701918             -0.671131  \n",
       "4             0.278574 -1.322039 -0.309348  -0.701918             -0.671131  \n",
       "...                ...       ...       ...        ...                   ...  \n",
       "135046        0.278574 -1.322039  0.457019  -0.701918             -0.671131  \n",
       "135047        0.278574 -0.353086  0.457019   1.424668              0.650473  \n",
       "135048        0.278574 -0.353086  0.457019  -0.701918              0.650473  \n",
       "135049        0.278574 -0.837562  0.457019   1.424668             -0.671131  \n",
       "135050        0.278574  1.584820 -1.075715  -0.701918             -1.992736  \n",
       "\n",
       "[135051 rows x 343 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_preprocessed = pd.read_csv('arvato_data/CUSTOMERS_cleaned.csv', sep=';')\n",
    "customers_preprocessed.drop(customers_preprocessed.columns[0], axis=1, inplace=True)\n",
    "customers_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform the customer data with the PCA and KMeans models trained on the population data\n",
    "customers_pca = pca.transform(customers_preprocessed)\n",
    "prediction_customers = kmeans.predict(customers_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the customer clusters for plotting; get percentage and counts\n",
    "customer_cluster = pd.DataFrame({'cluster':prediction_customers})\n",
    "customer_counts = customer_cluster.groupby(['cluster']).size().reset_index(name='counts')\n",
    "customer_counts['percent'] = customer_counts['counts']/customer_cluster.shape[0]*100\n",
    "customer_counts['type'] = 'Customers'\n",
    "t_df=pd.DataFrame({'cluster':list(range(14)), 'counts':[0]*14, 'percent':[0]*14})\n",
    "customer_counts = pd.merge(customer_counts,t_df, on='cluster', how='right').fillna(0)\n",
    "\n",
    "#prepare the customer clusters for plotting; get percentage and counts\n",
    "global_cluster = pd.DataFrame({'cluster':pop_predict})\n",
    "global_counts = global_cluster.groupby(['cluster']).size().reset_index(name='counts')\n",
    "global_counts['percent'] = global_counts['counts']/global_cluster.shape[0]*100\n",
    "global_counts['type'] = 'Population'\n",
    "\n",
    "t_df=pd.DataFrame({'cluster':list(range(14)), 'counts':[0]*14, 'percent':[0]*14})\n",
    "global_counts = pd.merge(global_counts,t_df, on='cluster', how='right').fillna(0)\n",
    "customer_counts = plot_df.append(gc_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "sns.barplot(x='cluster', y='percent_x', hue='type', data=plot_df)\n",
    "plt.title(\"Cluster Comparison\", size=16)\n",
    "plt.ylabel('Percent of Total')\n",
    "plt.xlabel('Cluster Num')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig('clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      population_median  customer_median  difference\n",
      "GREEN_AVANTGARDE              -0.531199         0.983527    1.514726\n",
      "ZABEOTYP                       0.427243        -1.075715    1.502958\n",
      "D19_BANKEN_GROSS               0.819077        -0.341749    1.160826\n",
      "D19_GESAMT_ANZ_24              2.110764         1.198492    0.912273\n",
      "CJT_TYP_6                     -0.301412         0.583731    0.885143\n",
      "D19_HAUS_DEKO                 -0.493998         0.368367    0.862365\n",
      "ALTERSKATEGORIE_GROB           0.164104        -0.671131    0.835236\n",
      "FINANZ_VORSORGER              -0.322522         0.503517    0.826039\n",
      "CJT_TYP_5                     -0.179239         0.623102    0.802341\n",
      "KBA05_MOD8                    -0.258143         0.492972    0.751116\n",
      "                   population_median  customer_median  difference\n",
      "FINANZTYP                  -1.353541         0.430541    1.784081\n",
      "ANREDE_KZ                   0.957594        -0.701918    1.659512\n",
      "AKT_DAT_KL                  1.249407        -0.369655    1.619062\n",
      "D19_SONSTIGE               -0.893557         0.651692    1.545248\n",
      "VERS_TYP                   -0.569915         0.910566    1.480481\n",
      "FINANZ_MINIMALIST          -0.746967         0.718502    1.465470\n",
      "HEALTH_TYP                 -0.062607         1.259568    1.322175\n",
      "RT_KEIN_ANREIZ              1.261977        -0.005341    1.267318\n",
      "D19_KONSUMTYP_MAX           0.743361        -0.348789    1.092150\n",
      "D19_KONSUMTYP               0.851068        -0.010221    0.861289\n",
      "                   population_median  customer_median  difference\n",
      "GEBURTSJAHR                -1.239735         0.670094    1.909829\n",
      "ANREDE_KZ                   0.957594        -0.701918    1.659512\n",
      "D19_SONSTIGE               -0.893557         0.651692    1.545248\n",
      "KBA05_MAXAH                -0.258385         0.946920    1.205305\n",
      "KBA13_CCM_3001             -1.061181         0.091313    1.152494\n",
      "D19_KONSUMTYP_MAX           0.743361        -0.348789    1.092150\n",
      "KBA05_ANTG1                -1.065787        -0.152652    0.913135\n",
      "SEMIO_DOM                   0.231045        -0.647686    0.878731\n",
      "D19_KONSUMTYP               0.851068        -0.010221    0.861289\n",
      "RT_KEIN_ANREIZ             -0.856498        -0.005341    0.851157\n",
      "                   population_median  customer_median  difference\n",
      "CJT_TYP_3                  -0.922908         0.628304    1.551212\n",
      "D19_SONSTIGE               -0.893557         0.651692    1.545248\n",
      "AKT_DAT_KL                  0.975417        -0.369655    1.345072\n",
      "KBA13_ANTG2                 0.221365         1.458947    1.237582\n",
      "FINANZ_HAUSBAUER            0.584621         1.704184    1.119564\n",
      "KBA05_MOD1                 -0.877979         0.231829    1.109809\n",
      "RT_UEBERGROESSE            -0.001109        -1.108760    1.107651\n",
      "D19_KONSUMTYP_MAX           0.743361        -0.348789    1.092150\n",
      "KBA13_HALTER_45             0.912295        -0.082700    0.994995\n",
      "KBA13_FIAT                 -0.131099         0.791021    0.922120\n"
     ]
    }
   ],
   "source": [
    "def describe_cluster(df1,df2,cluster):\n",
    "\n",
    "    df1_T = df1[df1['cluster']==cluster].describe().T.sort_values(by='50%',ascending=False)['50%']\n",
    "    df2_T = df2[df2['cluster']==cluster].describe().T.sort_values(by='50%',ascending=False)['50%']\n",
    "    df_concat = pd.concat([df1_T,df2_T],axis=1).dropna()\n",
    "    df_concat.columns = ['population_median', 'customer_median']\n",
    "    df_concat['difference'] = np.abs(df_concat.population_median - df_concat.customer_median)\n",
    "    df_concat = df_concat.sort_values(by='difference', ascending=False)\n",
    "    print(df_concat.head(10))\n",
    "\n",
    "azdias_preprocessed['cluster'] = pop_predict\n",
    "customers_preprocessed['cluster'] = prediction_customers\n",
    "\n",
    "describe_cluster(azdias_preprocessed,customers_preprocessed,0)\n",
    "describe_cluster(azdias_preprocessed,customers_preprocessed,6)\n",
    "describe_cluster(azdias_preprocessed,customers_preprocessed,8)\n",
    "describe_cluster(azdias_preprocessed,customers_preprocessed,12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and transform data\n",
    "mailout_train = pd.read_csv('arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', dtype={18:'str',19:'str'}, sep=';')\n",
    "mailout_test = pd.read_csv('arvato_data/Udacity_MAILOUT_052018_TEST.csv', dtype={18:'str',19:'str'}, sep=';')\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "#    print(mailout_train.info())\n",
    "\n",
    "    df_na_dropped = df.dropna(thresh=330)\n",
    "\n",
    "    train_labels = df_na_dropped['RESPONSE']\n",
    "    df_na_dropped = df_na_dropped.drop(['RESPONSE'], axis=1)\n",
    "    \n",
    "    #    print(mailout_train_dropped.info())\n",
    "    df_na_dropped.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    df_na_dropped.loc[:, 'OST_WEST_KZ'].replace({'W':0, 'O':1}, inplace=True);\n",
    "\n",
    "    imp = SimpleImputer(missing_values=float(\"NaN\"), strategy=\"most_frequent\", copy = False)\n",
    "    train_features = imp.fit_transform(df_na_dropped)\n",
    "    \n",
    "    s_scaler = StandardScaler()\n",
    "    train_features = s_scaler.fit_transform(train_features)\n",
    "    return(train_features, train_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42962, 367)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42962 entries, 0 to 42961\n",
      "Columns: 367 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(94), object(6)\n",
      "memory usage: 120.3+ MB\n",
      "None\n",
      "                LNR      AGER_TYP    AKT_DAT_KL      ALTER_HH  ALTER_KIND1  \\\n",
      "count  42962.000000  42962.000000  35993.000000  35993.000000  1988.000000   \n",
      "mean   42803.120129      0.542922      1.525241     10.285556    12.606137   \n",
      "std    24778.339984      1.412924      1.741500      6.082610     3.924976   \n",
      "min        1.000000     -1.000000      1.000000      0.000000     2.000000   \n",
      "25%    21284.250000     -1.000000      1.000000      8.000000     9.000000   \n",
      "50%    42710.000000      1.000000      1.000000     10.000000    13.000000   \n",
      "75%    64340.500000      2.000000      1.000000     15.000000    16.000000   \n",
      "max    85795.000000      3.000000      9.000000     21.000000    18.000000   \n",
      "\n",
      "       ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  \\\n",
      "count   756.000000   174.000000    41.000000          34807.000000   \n",
      "mean     13.783069    14.655172    14.195122              9.855058   \n",
      "std       3.065817     2.615329     3.034959              4.373539   \n",
      "min       5.000000     6.000000     6.000000              0.000000   \n",
      "25%      12.000000    13.000000    13.000000              8.000000   \n",
      "50%      14.000000    15.000000    15.000000             10.000000   \n",
      "75%      16.000000    17.000000    17.000000             13.000000   \n",
      "max      18.000000    18.000000    18.000000             25.000000   \n",
      "\n",
      "       ANZ_HAUSHALTE_AKTIV  ...      VK_DHT4A    VK_DISTANZ       VK_ZG11  \\\n",
      "count         35185.000000  ...  35695.000000  35695.000000  35695.000000   \n",
      "mean              6.706096  ...      4.318644      4.505953      3.116963   \n",
      "std              15.151790  ...      3.165199      3.289502      2.534331   \n",
      "min               0.000000  ...      1.000000      1.000000      1.000000   \n",
      "25%               1.000000  ...      1.000000      2.000000      1.000000   \n",
      "50%               2.000000  ...      3.000000      4.000000      2.000000   \n",
      "75%               7.000000  ...      7.000000      7.000000      4.000000   \n",
      "max             438.000000  ...     11.000000     13.000000     11.000000   \n",
      "\n",
      "       W_KEIT_KIND_HH  WOHNDAUER_2008      WOHNLAGE      ZABEOTYP  \\\n",
      "count    33284.000000    35993.000000  35185.000000  42962.000000   \n",
      "mean         4.488403        8.729947      4.059685      2.804199   \n",
      "std          1.889573        1.010545      2.046697      1.121585   \n",
      "min          0.000000        1.000000      0.000000      1.000000   \n",
      "25%          3.000000        9.000000      3.000000      3.000000   \n",
      "50%          6.000000        9.000000      3.000000      3.000000   \n",
      "75%          6.000000        9.000000      7.000000      3.000000   \n",
      "max          6.000000        9.000000      8.000000      6.000000   \n",
      "\n",
      "           RESPONSE     ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
      "count  42962.000000  42962.000000          42962.000000  \n",
      "mean       0.012383      1.595084              3.213910  \n",
      "std        0.110589      0.490881              1.067475  \n",
      "min        0.000000      1.000000              1.000000  \n",
      "25%        0.000000      1.000000              3.000000  \n",
      "50%        0.000000      2.000000              4.000000  \n",
      "75%        0.000000      2.000000              4.000000  \n",
      "max        1.000000      2.000000              9.000000  \n",
      "\n",
      "[8 rows x 361 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mailout_train.shape)\n",
    "print(mailout_train.info())\n",
    "print(mailout_train.describe())\n",
    "mailout_train_processed,train_label = preprocess_data(mailout_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42833, 366)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42833 entries, 0 to 42832\n",
      "Columns: 366 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(93), object(6)\n",
      "memory usage: 119.6+ MB\n",
      "None\n",
      "                LNR      AGER_TYP    AKT_DAT_KL      ALTER_HH  ALTER_KIND1  \\\n",
      "count  42833.000000  42833.000000  35944.000000  35944.000000  2013.000000   \n",
      "mean   42993.165620      0.537436      1.518890     10.239511    12.534029   \n",
      "std    24755.599728      1.414777      1.737441      6.109680     3.996079   \n",
      "min        2.000000     -1.000000      1.000000      0.000000     2.000000   \n",
      "25%    21650.000000     -1.000000      1.000000      8.000000     9.000000   \n",
      "50%    43054.000000      1.000000      1.000000     10.000000    13.000000   \n",
      "75%    64352.000000      2.000000      1.000000     15.000000    16.000000   \n",
      "max    85794.000000      3.000000      9.000000     21.000000    18.000000   \n",
      "\n",
      "       ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  \\\n",
      "count   762.000000   201.000000    39.000000          34715.000000   \n",
      "mean     13.942257    14.442786    14.410256              9.822584   \n",
      "std       3.142155     2.787106     2.279404              4.410937   \n",
      "min       4.000000     6.000000     9.000000              0.000000   \n",
      "25%      12.000000    13.000000    13.000000              8.000000   \n",
      "50%      14.000000    15.000000    14.000000             10.000000   \n",
      "75%      17.000000    17.000000    16.000000             13.000000   \n",
      "max      18.000000    18.000000    18.000000             25.000000   \n",
      "\n",
      "       ANZ_HAUSHALTE_AKTIV  ...           VHN      VK_DHT4A    VK_DISTANZ  \\\n",
      "count         35206.000000  ...  34530.000000  35658.000000  35658.000000   \n",
      "mean              6.749986  ...      2.372401      4.308682      4.488474   \n",
      "std              14.839779  ...      1.151531      3.169149      3.274829   \n",
      "min               0.000000  ...      0.000000      1.000000      1.000000   \n",
      "25%               1.000000  ...      2.000000      1.000000      2.000000   \n",
      "50%               2.000000  ...      2.000000      3.000000      4.000000   \n",
      "75%               7.000000  ...      3.000000      7.000000      7.000000   \n",
      "max             379.000000  ...      4.000000     11.000000     13.000000   \n",
      "\n",
      "            VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008      WOHNLAGE  \\\n",
      "count  35658.000000    33214.000000    35944.000000  35206.000000   \n",
      "mean       3.090078        4.489282        8.727437      4.088280   \n",
      "std        2.510134        1.886903        1.013702      2.053977   \n",
      "min        1.000000        0.000000        1.000000      0.000000   \n",
      "25%        1.000000        3.000000        9.000000      3.000000   \n",
      "50%        2.000000        6.000000        9.000000      3.000000   \n",
      "75%        4.000000        6.000000        9.000000      7.000000   \n",
      "max       11.000000        6.000000        9.000000      8.000000   \n",
      "\n",
      "           ZABEOTYP     ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
      "count  42833.000000  42833.000000          42833.000000  \n",
      "mean       2.800037      1.595475              3.220484  \n",
      "std        1.120624      0.490806              1.069753  \n",
      "min        1.000000      1.000000              1.000000  \n",
      "25%        3.000000      1.000000              3.000000  \n",
      "50%        3.000000      2.000000              4.000000  \n",
      "75%        3.000000      2.000000              4.000000  \n",
      "max        6.000000      2.000000              9.000000  \n",
      "\n",
      "[8 rows x 360 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mailout_test.shape)\n",
    "print(mailout_test.info())\n",
    "print(mailout_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KBA05_MOD4        20.13\n",
       "KBA05_MOD3        20.13\n",
       "KBA05_MOD2        20.13\n",
       "KBA05_MOD1        20.13\n",
       "KBA05_MAXVORB     20.13\n",
       "KBA05_MOTRAD      20.13\n",
       "KBA05_MAXHERST    20.13\n",
       "KBA05_MAXBJ       20.13\n",
       "KBA05_MAXAH       20.13\n",
       "KBA05_KW3         20.13\n",
       "MOBI_REGIO        20.13\n",
       "KBA05_KW2         20.13\n",
       "W_KEIT_KIND_HH    22.53\n",
       "HH_DELTA_FLAG     22.53\n",
       "EXTSEL992         37.12\n",
       "KK_KUNDENTYP      58.93\n",
       "ALTER_KIND1       95.37\n",
       "ALTER_KIND2       98.24\n",
       "ALTER_KIND3       99.59\n",
       "ALTER_KIND4       99.90\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_missing = mailout_train.isna().mean().round(4) * 100\n",
    "mailout_train_missing.sort_values(inplace=True)\n",
    "mailout_train_missing.tail(20)\n",
    "# Number of Nans\n",
    "temp_df = mailout_train.drop(drop_cols, axis=1)\n",
    "mailout_missing_cols = temp_df.isna().sum()\n",
    "mailout_missing_cols = mailout_missing_cols[mailout_missing_cols> 0]\n",
    "mailout_missing_cols.index\n",
    "#mailout_train_missing.sort_values(inplace=True)\n",
    "#mailout_train_missing.tail(20)\n",
    "print(type(mailout_missing_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(mailout_train['CAMEO_DEU_2015'].nunique())\n",
    "print(mailout_train.iloc[22398, :20])\n",
    "print(mailout_train['CAMEO_DEU_2015'].unique())\n",
    "print(mailout_train['CAMEO_DEUG_2015'].unique())\n",
    "print(mailout_train['CAMEO_INTL_2015'].unique())\n",
    "#CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP\n",
    "mailout_train[mailout_train.eq('1994-03-23 00:00:00').any(1)]\n",
    "print(mailout_train.iloc[42859, 80:130])\n",
    "print(mailout_train['OST_WEST_KZ'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=3, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=450, score=0.717, total=  21.4s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=450 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=450, score=0.701, total=  19.0s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=450 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=450, score=0.776, total=  19.1s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=450 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   59.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=450, score=0.737, total=  19.2s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=450 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=450, score=0.797, total=  25.0s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=500, score=0.716, total=  22.0s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=500, score=0.719, total=  22.1s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=500, score=0.773, total=  21.6s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=500, score=0.750, total=  21.9s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=500, score=0.792, total=  27.9s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=550, score=0.724, total=  29.2s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=550, score=0.713, total=  30.3s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=550, score=0.775, total=  28.0s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=550, score=0.745, total=  30.9s\n",
      "[CV] max_depth=3, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=4, n_estimators=550, score=0.794, total= 2.4min\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=450, score=0.720, total=  20.9s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=450, score=0.711, total=  21.9s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=450, score=0.770, total=  25.4s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=450, score=0.743, total=  26.0s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=450, score=0.794, total=  31.3s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=500, score=0.722, total= 1.0min\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=500, score=0.712, total= 1.2min\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=500, score=0.782, total=  47.6s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=500, score=0.737, total=  42.5s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=500, score=0.790, total=  44.2s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=550, score=0.716, total=  49.3s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=550, score=0.717, total=  39.6s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=550, score=0.777, total=  35.5s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=550, score=0.747, total=  34.1s\n",
      "[CV] max_depth=3, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=5, n_estimators=550, score=0.797, total=  34.1s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=450, score=0.705, total=  30.4s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=450, score=0.723, total=  31.4s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=450, score=0.780, total=  29.8s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=450, score=0.745, total=  27.6s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=450, score=0.798, total=  26.5s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=500, score=0.715, total=  32.4s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=500, score=0.718, total=  29.0s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=500, score=0.768, total=  28.8s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=500, score=0.751, total=  31.2s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=500, score=0.798, total=  31.8s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=550, score=0.711, total=  38.1s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=550, score=0.724, total=  37.5s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=550, score=0.776, total=  29.4s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=550, score=0.751, total=  36.4s\n",
      "[CV] max_depth=3, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=3, min_samples_split=6, n_estimators=550, score=0.795, total=  36.2s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=450, score=0.723, total=  33.3s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=450, score=0.715, total=  35.8s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=450, score=0.776, total=  34.7s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=450, score=0.745, total=  45.1s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=450, score=0.797, total=  47.4s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=500, score=0.718, total=  42.7s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=500, score=0.724, total=  50.9s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=500, score=0.784, total=  45.9s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=500, score=0.750, total=  44.7s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=500, score=0.805, total=  45.0s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=550, score=0.717, total=  49.1s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=550, score=0.724, total=  49.3s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=550 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=550, score=0.781, total=  44.2s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=550, score=0.746, total=  48.9s\n",
      "[CV] max_depth=4, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=4, n_estimators=550, score=0.795, total=  47.3s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=450, score=0.712, total=  32.1s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=450, score=0.730, total=  30.4s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=450, score=0.787, total=  31.7s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=450, score=0.744, total=  32.0s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=450, score=0.797, total=  31.2s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=500, score=0.722, total=  32.7s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=500, score=0.712, total=  34.6s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=500, score=0.778, total=  34.9s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=500, score=0.742, total=  36.0s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=500, score=0.797, total=  35.5s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=550, score=0.720, total=  40.4s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=550, score=0.719, total=  38.0s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=550, score=0.784, total=  38.3s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=550, score=0.745, total=  38.6s\n",
      "[CV] max_depth=4, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=5, n_estimators=550, score=0.803, total= 1.0min\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=450, score=0.722, total=  35.3s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=450, score=0.728, total=  34.8s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=450, score=0.780, total=12.6min\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=450, score=0.742, total=  27.0s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=450, score=0.796, total=  26.9s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=500, score=0.718, total=  29.1s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=500, score=0.724, total=  32.7s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=500, score=0.786, total=  40.6s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=500, score=0.746, total=  53.6s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=500, score=0.793, total=  48.5s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=550, score=0.718, total=  49.8s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=550, score=0.732, total=  44.3s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=550, score=0.780, total=  45.0s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=550, score=0.751, total=  34.2s\n",
      "[CV] max_depth=4, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=4, min_samples_split=6, n_estimators=550, score=0.794, total=  34.4s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=450, score=0.724, total=  39.3s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=450, score=0.718, total=  35.5s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=450, score=0.770, total=  33.6s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=450, score=0.740, total=  33.6s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=450, score=0.790, total=  33.9s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=500, score=0.716, total=  36.7s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=500, score=0.742, total=  37.3s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=500, score=0.782, total=  38.2s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=500, score=0.741, total=  45.6s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=500, score=0.787, total=  50.4s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=550, score=0.708, total=  48.1s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=550, score=0.731, total=  57.3s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=550, score=0.778, total=  51.9s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=550, score=0.751, total=  54.4s\n",
      "[CV] max_depth=5, min_samples_split=4, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=4, n_estimators=550, score=0.794, total=  48.9s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=450, score=0.713, total=  47.4s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=450, score=0.728, total=  40.4s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=450, score=0.780, total=  42.1s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=450, score=0.748, total=  38.4s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=450, score=0.792, total=  44.4s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=500 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=500, score=0.722, total=  50.6s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=500, score=0.719, total=  48.3s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=500, score=0.771, total=  54.1s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=500, score=0.747, total=  42.4s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=500, score=0.800, total=  38.7s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=550, score=0.705, total=  41.0s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=550, score=0.730, total=  41.1s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=550, score=0.770, total=  46.7s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=550, score=0.746, total=  43.0s\n",
      "[CV] max_depth=5, min_samples_split=5, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=5, n_estimators=550, score=0.798, total=  43.1s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=450, score=0.698, total=  35.9s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=450, score=0.733, total=  35.3s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=450, score=0.778, total=  33.8s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=450, score=0.755, total=  34.5s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=450 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=450, score=0.795, total=  34.2s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=500, score=0.705, total=  38.2s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=500, score=0.732, total=  52.3s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=500, score=0.771, total=  42.6s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=500, score=0.750, total=  48.8s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=500 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=500, score=0.785, total=  50.5s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=550, score=0.713, total=  57.8s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=550, score=0.730, total=  57.1s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=550, score=0.785, total=  46.1s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=550, score=0.743, total=  44.2s\n",
      "[CV] max_depth=5, min_samples_split=6, n_estimators=550 ..............\n",
      "[CV]  max_depth=5, min_samples_split=6, n_estimators=550, score=0.790, total=  48.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed: 100.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 500}\n",
      "0.7563233140378026\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[450, 500, 550],\n",
    "    \"max_depth\":[3, 4, 5],\n",
    "    \"min_samples_split\":[4, 5, 6],\n",
    "#    \"min_samples_leaf\":[2,4],\n",
    "}\n",
    "\n",
    "# n_estimators = [100, 300, 500, 800, 1200]\n",
    "#max_depth = [5, 8, 15, 25, 30]\n",
    "#min_samples_split = [2, 5, 10, 15, 100]\n",
    "#min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "cv = GridSearchCV(rfc,parameters,scoring='roc_auc', cv=5, verbose=5)\n",
    "cv.fit(mailout_train_processed,train_label.values.ravel())\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_processed\n",
    "sum(train_label.values)\n",
    "sum(mailout_train['RESPONSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34196 entries, 0 to 34195\n",
      "Columns: 353 entries, 0 to 352\n",
      "dtypes: float64(353)\n",
      "memory usage: 92.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(mailout_train_processed)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mailout_train_processed, train_label, stratify=train_label, test_size=0.2)\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 4, min_samples_split=5, n_estimators=500)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "#rfc.fit(mailout_train_processed,train_label.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "ROC score on testing data: 0.7281\n"
     ]
    }
   ],
   "source": [
    "preds = rfc.predict_proba(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"ROC score on testing data: {:.4f}\".format(roc_auc_score(y_test, preds[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test.head(10)\n",
    "\n",
    "#drop records with too many missing \n",
    "#mailout_test_dropped = mailout_test.dropna(thresh=330)\n",
    "mailout_test_dropped = mailout_test\n",
    "# Save the LNR for result index\n",
    "test_LNR = mailout_test_dropped['LNR']\n",
    "\n",
    "#    print(mailout_train_dropped.info())\n",
    "# Drop unneeded cols\n",
    "mailout_test_dropped.drop(drop_cols, axis=1, inplace=True)\n",
    "#mailout_test_dropped.drop(['RESPONSE'], axis=1, inplace=True)\n",
    "mailout_test_dropped.loc[:, 'OST_WEST_KZ'].replace({'W':0, 'O':1}, inplace=True);\n",
    "\n",
    "#impute NaNs\n",
    "imp = SimpleImputer(missing_values=float(\"NaN\"), strategy=\"most_frequent\", copy = False)\n",
    "test_features = imp.fit_transform(mailout_test_dropped)\n",
    "\n",
    "s_scaler = StandardScaler()\n",
    "test_features = s_scaler.fit_transform(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "rfc = RandomForestClassifier(max_depth = 4, min_samples_split=5, n_estimators=500)\n",
    "rfc.fit(X_train,y_train)\n",
    "preds = rfc.predict_proba(X_test)\n",
    "\n",
    "test_label = rfc.predict_proba(test_features)[:,1]\n",
    "\n",
    "submission = pd.DataFrame(test_label, index=test_LNR.astype('int32'),\n",
    "                          columns=[\"RESPONSE\"])\n",
    "\n",
    "submission.head()\n",
    "\n",
    "# Save file to submit\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9e2740b103e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Fit the ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmailout_train_processed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[1;32m--> 160\u001b[1;33m                 fn, *args, **kwargs)\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1045\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue_management_thread_wakeup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwakeup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_executor_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[0msubmit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\u001b[0m in \u001b[0;36m_ensure_executor_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes_management_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_workers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adjust_process_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_queue_management_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\u001b[0m in \u001b[0;36m_adjust_process_count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1010\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_process_worker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_exit_lock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworker_exit_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1012\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Adjust process count : {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0m_children\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\process.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_loky_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_loky_posix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\craig\\source\\workspaces\\coursera_ml_engineering\\capstone_project\\venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\popen_loky_win32.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspawn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_spawning_popen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initial LGBMRegressor tests\n",
    "reg = lgb.LGBMRegressor()\n",
    "\n",
    "clf = lgb.LGBMRegressor(random_state=0, learning_rate=0.001, max_depth=8, n_estimators=1500, )\n",
    "parameters = { 'num_leaves': [80, 100, 120, 140],\n",
    "              'min_data_in_leaf': [12, 15, 20, 25]\n",
    "             }\n",
    "\n",
    "\n",
    "# Grid search it\n",
    "cv = GridSearchCV(clf, parameters,scoring='roc_auc', cv=5, verbose=5, n_jobs=-1)\n",
    "\n",
    "# Fit the ...\n",
    "fitted = cv.fit(mailout_train_processed,train_label.values.ravel())\n",
    "\n",
    "\n",
    "# Get the estimator and predict\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] num_leaves=45 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=45, score=0.738, total= 2.1min\n",
      "[CV] num_leaves=45 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=45, score=0.777, total= 1.6min\n",
      "[CV] num_leaves=45 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=45, score=0.804, total= 2.2min\n",
      "[CV] num_leaves=45 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=45, score=0.765, total= 2.2min\n",
      "[CV] num_leaves=45 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=45, score=0.795, total= 2.2min\n",
      "[CV] num_leaves=50 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=50, score=0.743, total= 2.0min\n",
      "[CV] num_leaves=50 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=50, score=0.777, total= 1.8min\n",
      "[CV] num_leaves=50 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 14.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=50, score=0.800, total= 2.0min\n",
      "[CV] num_leaves=50 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 16.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=50, score=0.775, total= 1.7min\n",
      "[CV] num_leaves=50 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 18.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... num_leaves=50, score=0.801, total= 1.7min\n",
      "[CV] num_leaves=55 ...................................................\n",
      "[CV] ....................... num_leaves=55, score=0.735, total= 1.9min\n",
      "[CV] num_leaves=55 ...................................................\n",
      "[CV] ....................... num_leaves=55, score=0.779, total= 1.6min\n",
      "[CV] num_leaves=55 ...................................................\n",
      "[CV] ....................... num_leaves=55, score=0.799, total= 1.7min\n",
      "[CV] num_leaves=55 ...................................................\n",
      "[CV] ....................... num_leaves=55, score=0.770, total= 1.8min\n",
      "[CV] num_leaves=55 ...................................................\n",
      "[CV] ....................... num_leaves=55, score=0.799, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 28.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              importance_type='split', lambda_l2=0.1, learning_rate=0.001,\n",
      "              max_depth=13, min_child_samples=20, min_child_weight=0.001,\n",
      "              min_data_in_leaf=20, min_split_gain=0.0, n_estimators=1900,\n",
      "              n_jobs=-1, num_leaves=50, objective=None, random_state=0,\n",
      "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "              subsample_for_bin=200000, subsample_freq=0)\n",
      "{'num_leaves': 50}\n",
      "0.7792485355170605\n",
      "Wall time: 30min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Some basic training use LGBMRegressor\n",
    "\n",
    "clf = lgb.LGBMRegressor(\n",
    "            learning_rate=0.001, \n",
    "            lambda_l2 = 0.1,\n",
    "            random_state=0, \n",
    "            max_depth=13,\n",
    "            n_estimators=1900,\n",
    "            min_data_in_leaf=20 )\n",
    "\n",
    "parameters = {\n",
    "            'num_leaves': [45, 50, 55]\n",
    "             }\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring = 'roc_auc',  cv=5, verbose=10) # n_jobs=-1,\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(mailout_train_processed,train_label.values.ravel())\n",
    "\n",
    "# Get the estimator and predict\n",
    "print(grid_fit.best_estimator_)\n",
    "print(grid_fit.best_params_)\n",
    "print(grid_fit.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from several hyperparameter tuning runs.\n",
    "{'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 2000}\n",
    "0.7738214439485253\n",
    "\n",
    "{'min_data_in_leaf': 15, 'num_leaves': 80}\n",
    "0.7663591334356443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMRegressor(\n",
    "            learning_rate=0.001, \n",
    "            lambda_l2 = 0.1,\n",
    "            random_state=0, \n",
    "            max_depth=13,\n",
    "            n_estimators=1900,\n",
    "            min_data_in_leaf=20,\n",
    "            num_leaves=50)\n",
    "\n",
    "clf.fit(mailout_train_processed, train_label)\n",
    "# Prediction\n",
    "test_label = clf.predict(test_features)\n",
    "\n",
    "submission = pd.DataFrame(test_label, index=test_LNR.astype('int32'),\n",
    "                          columns=[\"RESPONSE\"])\n",
    "submission.head()\n",
    "\n",
    "# Save file to submit\n",
    "submission.to_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "lgb_preds = test_label\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 4, min_samples_split=5, n_estimators=500)\n",
    "rfc.fit(mailout_train_processed, train_label)\n",
    "rf_preds = rfc.predict_proba(test_features)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03163904 0.01598747 0.00379993 ... 0.00831696 0.04829675 0.03364624]\n",
      "[0.01774926 0.01750166 0.01237377 ... 0.01357825 0.01087199 0.01260128]\n"
     ]
    }
   ],
   "source": [
    "print(lgb_preds)\n",
    "print(rf_preds)\n",
    "test_label = (rf_preds+lgb_preds)/2\n",
    "\n",
    "submission = pd.DataFrame(test_label, index=test_LNR.astype('int32'),\n",
    "                          columns=[\"RESPONSE\"])\n",
    "\n",
    "submission.head()\n",
    "\n",
    "# Save file to submit\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "              importance_type='split', learning_rate=0.001, max_depth=10,\n",
      "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "              n_estimators=2000, n_jobs=-1, num_leaves=31, objective=None,\n",
      "              random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "{'learning_rate': 0.001, 'max_depth': 10, 'n_estimators': 2000}\n",
      "0.7738214439485253\n"
     ]
    }
   ],
   "source": [
    "print(grid_fit.best_estimator_)\n",
    "print(grid_fit.best_params_)\n",
    "print(grid_fit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', lambda_l2=0.1, learning_rate=0.001,\n",
    "              max_depth=12, min_child_samples=20, min_child_weight=0.001,\n",
    "              min_split_gain=0.0, n_estimators=2000, n_jobs=-1, num_leaves=31,\n",
    "              objective=None, random_state=0, reg_alpha=0.0, reg_lambda=0.0,\n",
    "              silent=True, subsample=1.0, subsample_for_bin=200000,\n",
    "              subsample_freq=0)\n",
    "{'max_depth': 12, 'n_estimators': 2000}\n",
    "0.7748209259235634\n",
    "Wall time: 1h 3min 38s\n",
    "    \n",
    "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', lambda_l2=0.1, learning_rate=0.001,\n",
    "              max_depth=13, min_child_samples=20, min_child_weight=0.001,\n",
    "              min_split_gain=0.0, n_estimators=1900, n_jobs=-1, num_leaves=31,\n",
    "              objective=None, random_state=0, reg_alpha=0.0, reg_lambda=0.0,\n",
    "              silent=True, subsample=1.0, subsample_for_bin=200000,\n",
    "              subsample_freq=0)\n",
    "{'max_depth': 13, 'n_estimators': 1900}\n",
    "0.7778164928266607\n",
    "Wall time: 1h 7min 34s   \n",
    "    \n",
    "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', lambda_l2=0.1, learning_rate=0.001,\n",
    "              max_depth=13, min_child_samples=20, min_child_weight=0.001,\n",
    "              min_data_in_leaf=20, min_split_gain=0.0, n_estimators=1900,\n",
    "              n_jobs=-1, num_leaves=31, objective=None, random_state=0,\n",
    "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
    "              subsample_for_bin=200000, subsample_freq=0)\n",
    "{'min_data_in_leaf': 20}\n",
    "0.7778164928266607\n",
    "Wall time: 24min 20s    \n",
    "    \n",
    "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', lambda_l2=0.1, learning_rate=0.001,\n",
    "              max_depth=13, min_child_samples=20, min_child_weight=0.001,\n",
    "              min_data_in_leaf=20, min_split_gain=0.0, n_estimators=1900,\n",
    "              n_jobs=-1, num_leaves=50, objective=None, random_state=0,\n",
    "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
    "              subsample_for_bin=200000, subsample_freq=0)\n",
    "{'num_leaves': 50}\n",
    "0.7792485355170605\n",
    "Wall time: 27min 33s  \n",
    "    \n",
    "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', lambda_l2=0.1, learning_rate=0.001,\n",
    "              max_depth=13, min_child_samples=20, min_child_weight=0.001,\n",
    "              min_data_in_leaf=20, min_split_gain=0.0, n_estimators=1900,\n",
    "              n_jobs=-1, num_leaves=50, objective=None, random_state=0,\n",
    "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
    "              subsample_for_bin=200000, subsample_freq=0)\n",
    "{'num_leaves': 50}\n",
    "0.7792485355170605\n",
    "Wall time: 30min 32s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] n_estimators=95 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=95, score=0.757, total=  18.9s\n",
      "[CV] n_estimators=95 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=95, score=0.775, total=  24.7s\n",
      "[CV] n_estimators=95 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   43.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=95, score=0.817, total=  20.8s\n",
      "[CV] n_estimators=95 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=95, score=0.788, total=  22.8s\n",
      "[CV] n_estimators=95 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=95, score=0.785, total=  20.7s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.761, total=  21.5s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.774, total=  20.4s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.815, total=  20.8s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.784, total=  20.6s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.791, total=  20.4s\n",
      "[CV] n_estimators=105 ................................................\n",
      "[CV] .................... n_estimators=105, score=0.759, total=  21.2s\n",
      "[CV] n_estimators=105 ................................................\n",
      "[CV] .................... n_estimators=105, score=0.772, total=  21.5s\n",
      "[CV] n_estimators=105 ................................................\n",
      "[CV] .................... n_estimators=105, score=0.818, total=  20.4s\n",
      "[CV] n_estimators=105 ................................................\n",
      "[CV] .................... n_estimators=105, score=0.779, total=  20.3s\n",
      "[CV] n_estimators=105 ................................................\n",
      "[CV] .................... n_estimators=105, score=0.790, total=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=0.6, tree_method=None,\n",
      "             validate_parameters=False, verbosity=None)\n",
      "{'n_estimators': 100}\n",
      "0.7850574707646799\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training use XGBRegressor\n",
    "xgbr = XGBRegressor(objective='binary:logistic',  learning_rate=0.1,\n",
    "                    random_state=42, max_depth=3, min_child_weight=3,\n",
    "                    n_estimators=100, gamma=0.0, subsample=0.6, colsample_bytree=0.7)\n",
    "\n",
    "parameters = {\n",
    "            'n_estimators':[95, 100, 105]\n",
    "            #'learning_rate':[0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "             }\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "gcv = GridSearchCV(xgbr, parameters, scoring = 'roc_auc',  cv=5, verbose=10) #, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "gcv_fit = gcv.fit(mailout_train_processed,train_label.values.ravel())\n",
    "\n",
    "# Get the estimator and predict\n",
    "print(gcv_fit.best_estimator_)\n",
    "print(gcv_fit.best_params_)\n",
    "print(gcv_fit.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from XGBRegressor grid search runs\n",
    "'learning_rate':[0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    " XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=0.6, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "{'learning_rate': 0.1}\n",
    "0.7850574707646799\n",
    "Wall time: 11min 16s\n",
    "    \n",
    "'subsample':[0.55, 0.6, 0.65],\n",
    "'colsample_bytree':[0.65, 0.7, 0.75, 0.8]\n",
    "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=0.6, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "{'colsample_bytree': 0.7, 'subsample': 0.6}\n",
    "0.7850574707646799\n",
    "Wall time: 20min 36s\n",
    "\n",
    "'subsample':[0.5, 0.6, 0.7],\n",
    "'colsample_bytree':[0.5, 0.6, 0.7]\n",
    "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=0.6, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "{'colsample_bytree': 0.7, 'subsample': 0.6}\n",
    "0.7850574707646799\n",
    "Wall time: 14min 52s\n",
    "\n",
    "'gamma':[0.0, 0.2, 0.4, 0.6]\n",
    "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0.0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "{'gamma': 0.0}\n",
    "0.777715514546973\n",
    "Wall time: 9min 44s\n",
    "    \n",
    "\n",
    "parameters = {\n",
    "            'max_depth':[3, 6, 10],\n",
    "            'min_child_weight':[2, 4, 6]\n",
    "             }\n",
    "\n",
    "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.09, max_delta_step=0, max_depth=3,\n",
    "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "{'max_depth': 3, 'min_child_weight': 2}\n",
    "0.7789512979471498\n",
    "Wall time: 41min 19s\n",
    "\n",
    "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.09, max_delta_step=0, max_depth=6,\n",
    "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
    "             n_estimators=90, n_jobs=0, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=42, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)\n",
    "{'n_estimators': 90}\n",
    "0.773693662969211\n",
    "Wall time: 15min 18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(objective='binary:logistic',  learning_rate=0.1,\n",
    "                    random_state=42, max_depth=3, min_child_weight=3,\n",
    "                    n_estimators=100, gamma=0.0, subsample=0.6, colsample_bytree=0.7)\n",
    "\n",
    "xgbr.fit(mailout_train_processed, train_label)\n",
    "# Prediction\n",
    "test_label = xgbr.predict(test_features)\n",
    "\n",
    "submission = pd.DataFrame(test_label, index=test_LNR.astype('int32'),\n",
    "                          columns=[\"RESPONSE\"])\n",
    "submission.head()\n",
    "\n",
    "# Save file to submit\n",
    "submission.to_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03163904 0.01598747 0.00379993 ... 0.00831696 0.04829675 0.03364624]\n",
      "[0.01813488 0.01706819 0.01552554 ... 0.01252018 0.01151781 0.01394867]\n",
      "[0.05178991 0.01550879 0.00361368 ... 0.01679283 0.02336414 0.01460921]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNR</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>0.033855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0.016188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>0.007646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>0.006589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>0.007019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RESPONSE\n",
       "LNR           \n",
       "1754  0.033855\n",
       "1770  0.016188\n",
       "1465  0.007646\n",
       "1470  0.006589\n",
       "1478  0.007019"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_preds = test_label\n",
    "\n",
    "clf = lgb.LGBMRegressor(\n",
    "            learning_rate=0.001, \n",
    "            lambda_l2 = 0.1,\n",
    "            random_state=0, \n",
    "            max_depth=13,\n",
    "            n_estimators=1900,\n",
    "            min_data_in_leaf=20,\n",
    "            num_leaves=50)\n",
    "\n",
    "clf.fit(mailout_train_processed, train_label)\n",
    "# Prediction\n",
    "lgb_preds = clf.predict(test_features)\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 4, min_samples_split=5, n_estimators=500)\n",
    "rfc.fit(mailout_train_processed, train_label)\n",
    "rf_preds = rfc.predict_proba(test_features)[:,1]\n",
    "\n",
    "print(lgb_preds)\n",
    "print(rf_preds)\n",
    "print(xgbr_preds)\n",
    "test_label = (xgbr_preds+rf_preds+lgb_preds)/3\n",
    "\n",
    "submission = pd.DataFrame(test_label, index=test_LNR.astype('int32'),\n",
    "                          columns=[\"RESPONSE\"])\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save file to submit\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
